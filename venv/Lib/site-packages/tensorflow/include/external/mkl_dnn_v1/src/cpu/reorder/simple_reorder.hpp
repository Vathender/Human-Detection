/*******************************************************************************
* Copyright 2016-2021 Intel Corporation
*
* Licensed under the Apache License, Version 2.0 (the "License");
* you may not use this file except in compliance with the License.
* You may obtain a copy of the License at
*
*     http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing, software
* distributed under the License is distributed on an "AS IS" BASIS,
* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
* See the License for the specific language governing permissions and
* limitations under the License.
*******************************************************************************/

#ifndef CPU_REORDER_SIMPLE_REORDER_HPP
#define CPU_REORDER_SIMPLE_REORDER_HPP

#include <assert.h>

#include "common/bfloat16.hpp"
#include "common/c_types_map.hpp"
#include "common/dnnl_thread.hpp"
#include "common/math_utils.hpp"
#include "common/primitive.hpp"
#include "common/primitive_attr.hpp"
#include "common/tag_traits.hpp"
#include "common/type_helpers.hpp"
#include "common/utils.hpp"

#include "cpu/cpu_primitive.hpp"
#include "cpu/reorder/cpu_reorder_pd.hpp"

#include "cpu/simple_q10n.hpp"

namespace dnnl {
namespace impl {
namespace cpu {

using bd = block_dim_t;
using ib = inner_blk_t;

template <impl::data_type_t type>
using data_t = typename prec_traits<type>::type;

template <impl::data_type_t type_i, impl::data_type_t type_o>
using _qz_a1b0 = qz_a1b0<data_t<type_i>, data_t<type_o>>;

template <impl::data_type_t type_i, impl::data_type_t type_o>
using _qz = qz<data_t<type_i>, data_t<type_o>>;

namespace fmt_order {
const bool keep = true;
const bool reverse = false;
const bool any = keep;
} // namespace fmt_order

namespace spec {
struct direct_copy {};
struct direct_copy_except_dim_0 {};
struct reference {};
struct conv_req_comp {}; // {s8, u8: asymmetric quantization}
} // namespace spec

#define SIMPLE_REORDER_TEMPL_DECL \
    impl::data_type_t type_i, impl::format_tag_t tag_i, \
            impl::data_type_t type_o, impl::format_tag_t tag_o, \
            bool order_keep
#define SIMPLE_REORDER_TEMPL_CALL type_i, tag_i, type_o, tag_o, order_keep

#define DECLARE_COMMON_PARAMS() \
    auto input = CTX_IN_MEM(const data_t<type_i> *, DNNL_ARG_FROM); \
    auto output = CTX_OUT_MEM(data_t<type_o> *, DNNL_ARG_TO); \
    const auto &scratchpad = ctx.get_scratchpad_grantor(); \
    MAYBE_UNUSED(scratchpad); \
    const auto input_d = ctx.memory_mdw(DNNL_ARG_FROM, pd->src_md()); \
    const auto output_d = ctx.memory_mdw(DNNL_ARG_TO, pd->dst_md()); \
    const float alpha = pd->alpha(); \
    MAYBE_UNUSED(alpha); \
    const float beta = pd->beta(); \
    MAYBE_UNUSED(beta);

#define GET_SCRATCHPAD_SIZE_ZERO() \
    static size_t get_scratchpad_size(const memory_desc_wrapper &input_d, \
            const memory_desc_wrapper &output_d) { \
        return 0; \
    }

/* specific reorders: common template */
template <SIMPLE_REORDER_TEMPL_DECL, typename spec = void>
struct simple_reorder_impl {};

namespace {
inline bool simple_fmt_check(bool order_keep, impl::format_tag_t tag_i,
        impl::format_tag_t tag_o, const memory_desc_wrapper &input_d,
        const memory_desc_wrapper &output_d) {
    if (input_d.has_runtime_dims_or_strides()) return false;
    return input_d.matches_tag(order_keep ? tag_i : tag_o)
            && output_d.matches_tag(order_keep ? tag_o : tag_i);
}
inline bool simple_po_check(const primitive_attr_t *attr) {
    const auto &po = attr->post_ops_;
    return po.len() == 0
            || (po.len() == 1 && po.contain(primitive_kind::sum, 0));
}
inline bool simple_attr_check(const primitive_attr_t *attr,
        bool many_scales_support, bool sum_support) {
    using smask_t = primitive_attr_t::skip_mask_t;
    smask_t skip_mask = smask_t::oscale;
    if (sum_support) skip_mask = skip_mask | smask_t::post_ops;
    if (!attr->has_default_values(skip_mask)) return false;
    if (!attr->defined()) return false;
    if (sum_support) simple_po_check(attr);
    if (many_scales_support) return true;
    return attr->output_scales_.mask_ == 0;
}
} // namespace

/* specific reorders: implementation */
template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<tag_i == format_tag::any
                        && utils::one_of(tag_o, format_tag::wio,
                                format_tag::wigo, format_tag::hwio,
                                format_tag::hwigo, format_tag::dhwio,
                                format_tag::dhwigo),
                spec::conv_req_comp>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        using namespace data_type;
        using namespace utils;

        if (input_d.has_runtime_dims_or_strides()) return false;

        const size_t D_mask = array_product(
                input_d.dims(), math::ilog2q(attr->output_scales_.mask_ + 1));
        static constexpr bool w_groups = one_of(
                tag_o, format_tag::wigo, format_tag::hwigo, format_tag::dhwigo);
        const int oc_idx = w_groups ? 1 : 0;
        const int oc = input_d.dims()[oc_idx];
        const int g = w_groups ? (input_d.dims()[0]) : 1;

        const bool req_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_s8s8;
        const bool req_asymmetric_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_asymmetric_src;

        auto mask_ok = [&](bool check, int mask) {
            return IMPLICATION(check, mask == (w_groups ? 0x3 : 0x1));
        };

        return simple_attr_check(attr, true, false)
                && output_d.matches_tag(tag_o) && input_d.is_plain()
                && (req_comp || req_asymmetric_comp)
                && mask_ok(req_comp, output_d.extra().compensation_mask)
                && mask_ok(req_asymmetric_comp,
                        output_d.extra().asymm_compensation_mask)
                && IMPLICATION(
                        req_comp, one_of(D_mask, (size_t)1, (size_t)g * oc))
                && one_of(input_d.data_type(), f32, s8, bf16)
                && output_d.data_type() == s8;
    }

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();

        static constexpr bool w_groups = utils::one_of(
                tag_o, format_tag::wigo, format_tag::hwigo, format_tag::dhwigo);
        static constexpr bool w_height
                = !utils::one_of(tag_o, format_tag::wio, format_tag::wigo);
        static constexpr bool w_depth
                = utils::one_of(tag_o, format_tag::dhwio, format_tag::dhwigo);

        const auto &dims = input_d.dims();
        const auto &pdims = output_d.padded_dims();

        const int G = w_groups ? dims[0] : 1;
        const int OC = dims[w_groups + 0];
        const int IC = dims[w_groups + 1];
        const int D = w_depth ? dims[w_groups + 2] : 1;
        const int H = w_height ? dims[w_groups + w_depth + 2] : 1;
        const int W = dims[w_groups + w_depth + w_height + 2];

        const float *scales = pd->attr()->output_scales_.scales_;
        const size_t D_mask = utils::array_product(input_d.dims(),
                math::ilog2q(pd->attr()->output_scales_.mask_ + 1));
        const bool req_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_s8s8;
        const bool has_asymmetric_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_asymmetric_src;

        assert(req_comp || has_asymmetric_comp);

        float adj_scale
                = (output_d.extra().flags & memory_extra_flags::scale_adjust)
                ? output_d.extra().scale_adjust
                : 1.f;

        size_t offset
                = G * pdims[w_groups + 0] * pdims[w_groups + 1] * D * H * W;
        size_t zp_offset = offset
                + (req_comp ? G * pdims[w_groups + 0] * sizeof(int32_t) : 0);
        int32_t *cp = req_comp ? reinterpret_cast<int32_t *>(output + offset)
                               : nullptr;
        int32_t *zp = has_asymmetric_comp
                ? reinterpret_cast<int32_t *>(output + zp_offset)
                : nullptr;

        parallel_nd(G, OC, [&](int g, int oc) {
            if (req_comp) cp[g * OC + oc] = 0;
            if (has_asymmetric_comp) zp[g * OC + oc] = 0;
            for_(int ic = 0; ic < IC; ic++)
            for_(int d = 0; d < D; d++)
            for_(int h = 0; h < H; h++)
            for (int w = 0; w < W; w++) {
                auto i = w_depth
                        ? input[input_d.blk_off<!w_groups>(g, oc, ic, d, h, w)]
                        : w_height ? input[input_d.blk_off<!w_groups>(
                                  g, oc, ic, h, w)]
                                   : input[input_d.blk_off<!w_groups>(
                                           g, oc, ic, w)];
                auto &o = w_depth
                        ? output[output_d.blk_off<!w_groups>(
                                g, oc, ic, d, h, w)]
                        : w_height ? output[output_d.blk_off<!w_groups>(
                                  g, oc, ic, h, w)]
                                   : output[output_d.blk_off<!w_groups>(
                                           g, oc, ic, w)];
                const float s = scales[(D_mask == 1) ? 0 : g * OC + oc];

                o = qz_b0<data_t<type_i>, data_t<type_o>>()(i, s * adj_scale);
                if (req_comp) cp[g * OC + oc] -= (int32_t)o;
                if (has_asymmetric_comp) zp[g * OC + oc] -= (int32_t)o;
            }
            if (req_comp) cp[g * OC + oc] *= 128;
        });
        return status::success;
    }
};

template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<
                (utils::one_of(tag_i, format_tag::iwo, format_tag::oiw,
                         format_tag::wio)
                        && utils::one_of(tag_o, format_tag::OIw4i16o4i,
                                format_tag::OIw4i32o4i, format_tag::OIw4i64o4i,
                                format_tag::OIw2i8o4i, format_tag::OIw4o4i))
                        || (utils::one_of(tag_i, format_tag::oi, format_tag::io)
                                && utils::one_of(tag_o, format_tag::OI4i16o4i,
                                        format_tag::OI4i32o4i,
                                        format_tag::OI4i64o4i))
                        || (utils::one_of(
                                    tag_i, format_tag::goiw, format_tag::wigo)
                                && utils::one_of(tag_o, format_tag::gOIw4i16o4i,
                                        format_tag::gOIw2i8o4i,
                                        format_tag::gOIw4o4i))
                        || (utils::one_of(tag_i, format_tag::ihwo,
                                    format_tag::hwio, format_tag::oihw)
                                && utils::one_of(tag_o, format_tag::OIhw4i16o4i,
                                        format_tag::OIhw4i32o4i,
                                        format_tag::OIhw4i64o4i,
                                        format_tag::OIhw2i8o4i,
                                        format_tag::OIhw4o4i))
                        || (utils::one_of(tag_i, format_tag::idhwo,
                                    format_tag::dhwio, format_tag::oidhw)
                                && utils::one_of(tag_o,
                                        format_tag::OIdhw4i16o4i,
                                        format_tag::OIdhw4i32o4i,
                                        format_tag::OIdhw4i64o4i,
                                        format_tag::OIdhw2i8o4i,
                                        format_tag::OIdhw4o4i))
                        || (utils::one_of(
                                    tag_i, format_tag::goihw, format_tag::hwigo)
                                && utils::one_of(tag_o, format_tag::gOIhw4o4i,
                                        format_tag::gOIhw2i8o4i,
                                        format_tag::gOIhw4i16o4i))
                        || (utils::one_of(tag_i, format_tag::goidhw)
                                && (utils::one_of(tag_o,
                                        format_tag::gOIdhw4i16o4i,
                                        format_tag::gOIdhw2i8o4i,
                                        format_tag::gOIdhw4o4i))),
                spec::conv_req_comp>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        using namespace format_tag;
        using namespace data_type;
        using namespace utils;

        if (input_d.has_runtime_dims_or_strides()) return false;

        const size_t D_mask = array_product(
                input_d.dims(), math::ilog2q(attr->output_scales_.mask_ + 1));
        const bool w_groups = !one_of(tag_o, OIw4i16o4i, OIw2i8o4i, OIw4o4i,
                OIhw4i16o4i, OIhw2i8o4i, OIhw4o4i, OIdhw4i16o4i, OIdhw2i8o4i,
                OIdhw4o4i, OI4i16o4i, OI4i32o4i, OI4i64o4i, OIw4i32o4i,
                OIw4i64o4i, OIhw4i32o4i, OIhw4i64o4i, OIdhw4i32o4i,
                OIdhw4i64o4i);
        const int oc = (input_d.dims()[w_groups ? 1 : 0]);
        const int g = w_groups ? input_d.dims()[0] : 1;

        const bool req_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_s8s8;
        const bool req_asymmetric_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_asymmetric_src;

        auto mask_ok = [&](bool check, int mask) {
            return IMPLICATION(check, mask == (w_groups ? 0x3 : 0x1));
        };

        return simple_attr_check(attr, true, false)
                && input_d.matches_tag(tag_i) && output_d.matches_tag(tag_o)
                && (req_comp || req_asymmetric_comp)
                && mask_ok(req_comp, output_d.extra().compensation_mask)
                && mask_ok(req_asymmetric_comp,
                        output_d.extra().asymm_compensation_mask)
                && IMPLICATION(
                        req_comp, one_of(D_mask, (size_t)1, (size_t)g * oc))
                && one_of(input_d.data_type(), f32, s8, bf16)
                && output_d.data_type() == s8;
    }

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();
        using namespace format_tag;

        static constexpr bool w_groups = !utils::one_of(tag_o, OIw4o4i,
                OIw4i16o4i, OIhw4i16o4i, OIdhw4i16o4i, OIhw4o4i, OIw2i8o4i,
                OIhw2i8o4i, OIdhw2i8o4i, OIdhw4o4i, OI4i16o4i, OI4i32o4i,
                OI4i64o4i, OIw4i32o4i, OIw4i64o4i, OIhw4i32o4i, OIhw4i64o4i,
                OIdhw4i32o4i, OIdhw4i64o4i);

        constexpr int is_0d
                = utils::one_of(tag_o, OI4i16o4i, OI4i32o4i, OI4i64o4i);
        constexpr int is_1d
                = utils::one_of(tag_o, gOIw4i16o4i, OIw4i16o4i, gOIw2i8o4i,
                        OIw2i8o4i, gOIw4o4i, OIw4o4i, OIw4i32o4i, OIw4i64o4i);
        constexpr int is_3d = utils::one_of(tag_o, gOIdhw4i16o4i, OIdhw4i16o4i,
                gOIdhw2i8o4i, OIdhw2i8o4i, gOIdhw4o4i, OIdhw4o4i, OIdhw4i32o4i,
                OIdhw4i64o4i);
        constexpr int icblksize = utils::one_of(tag_traits<tag_o>::inner_blks,
                                          ib::_4a4b, ib::_4b4c)
                ? 4
                : utils::one_of(tag_traits<tag_o>::inner_blks, ib::_2c8b4c,
                          ib::_2b8a4b)
                        ? 8
                        : 16;
        constexpr int ocblksize = tag_traits<tag_o>::inner_blks == ib::_4b32a4b
                ? 32
                : tag_traits<tag_o>::inner_blks == ib::_4b64a4b ? 64
                                                                : icblksize;

        const auto &plain_d = order_keep ? input_d : output_d;
        const auto &dims = input_d.dims();
        const auto &pdims
                = order_keep ? output_d.padded_dims() : input_d.padded_dims();

        const int G = w_groups ? dims[0] : 1;
        const int OC = dims[w_groups + 0];
        const int NB_OC = pdims[w_groups + 0] / ocblksize;
        const int IC = dims[w_groups + 1];
        const int NB_IC = pdims[w_groups + 1] / icblksize;
        const int D = is_3d ? dims[2 + w_groups] : 1;
        const int H = is_1d || is_0d ? 1 : dims[2 + w_groups + is_3d];
        const int W = is_0d ? 1 : dims[w_groups + is_3d + 3 - is_1d];

        const float *scales = pd->attr()->output_scales_.scales_;
        const size_t D_mask = utils::array_product(input_d.dims(),
                math::ilog2q(pd->attr()->output_scales_.mask_ + 1));
        const bool req_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_s8s8;
        const bool has_asymmetric_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_asymmetric_src;

        assert(req_comp || has_asymmetric_comp);

        float adj_scale
                = (output_d.extra().flags & memory_extra_flags::scale_adjust)
                ? output_d.extra().scale_adjust
                : 1.f;
        const bool broadcast_scales = (D_mask == 1);

        // This kernel is used primarily for tensors with multiple inner
        // blocks for which generic zero padding must be used.
        // TODO: apply zero padding inside parallel_nd()
        ctx.zero_pad_output(DNNL_ARG_TO);

        auto ker = [&](const data_t<type_i> *inp, data_t<type_o> *out,
                           int32_t *c, int32_t *zp, const float *s,
                           const int oc_block, const int ic_block) {
#define index AB_or_BC_blk_off<tag_traits<tag_o>::inner_blks>
            for_(int ic = 0; ic < ic_block; ++ic)
            for (int oc = 0; oc < oc_block; ++oc) {
                const auto plain_off
                        = oc * plain_d.blocking_desc().strides[w_groups + 0]
                        + ic * plain_d.blocking_desc().strides[w_groups + 1];
                out[index(oc, ic)] = qz_b0<data_t<type_i>, data_t<type_o>>()(
                        inp[plain_off],
                        s[broadcast_scales ? 0 : oc] * adj_scale);
                if (req_comp) c[oc] -= (128 * (int32_t)(out[index(oc, ic)]));
                if (has_asymmetric_comp)
                    zp[oc] -= (int32_t)(out[index(oc, ic)]);
            }
#undef index
        };

        constexpr int i_mult_ic = icblksize;
        constexpr int i_mult_oc = ocblksize;
        constexpr int o_mult = 1;

        size_t offset
                = G * pdims[w_groups + 0] * pdims[w_groups + 1] * D * H * W;
        size_t zp_offset = offset
                + (req_comp ? G * pdims[w_groups + 0] * sizeof(int32_t) : 0);
        int32_t *cp = req_comp ? reinterpret_cast<int32_t *>(output + offset)
                               : nullptr;
        int32_t *zp = has_asymmetric_comp
                ? reinterpret_cast<int32_t *>(output + zp_offset)
                : nullptr;
        parallel_nd(G * NB_OC * ocblksize, [&](int i) {
            if (req_comp) cp[i] = 0;
            if (has_asymmetric_comp) zp[i] = 0;
        });

#define wei_blk_off(md, g, o, i, d, h, w) \
    (is_0d ? (md).blk_off<!w_groups>(g, o, i) \
           : is_1d ? (md).blk_off<!w_groups>(g, o, i, w) \
                   : is_3d ? (md).blk_off<!w_groups>(g, o, i, d, h, w) \
                           : (md).blk_off<!w_groups>(g, o, i, h, w))
        parallel_nd(G, NB_OC, [&](int g, int O) {
            for_(int I = 0; I < NB_IC; I++)
            for_(int d = 0; d < D; d++)
            for_(int h = 0; h < H; h++)
            for (int w = 0; w < W; w++) {
                auto i = &input[wei_blk_off(
                        input_d, g, i_mult_oc * O, i_mult_ic * I, d, h, w)];
                auto o = &output[wei_blk_off(
                        output_d, g, o_mult * O, o_mult * I, d, h, w)];
                const int oc_block = nstl::min(ocblksize, OC - O * ocblksize);
                const int ic_block = nstl::min(icblksize, IC - I * icblksize);
                int _offset = (g * NB_OC + O) * ocblksize;
                ker(i, o, (order_keep && req_comp) ? &cp[_offset] : nullptr,
                        (order_keep && has_asymmetric_comp) ? &zp[_offset]
                                                            : nullptr,
                        &scales[broadcast_scales ? 0 : _offset], oc_block,
                        ic_block);
            }
        });

#undef wei_blk_off

        return status::success;
    }
};

/* Asymmetric Blocking */
template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<(utils::one_of(tag_i, format_tag::iwo,
                                           format_tag::oiw, format_tag::wio)
                                          && utils::one_of(
                                                  tag_o, format_tag::Owi16o))
                        || (utils::one_of(
                                    tag_i, format_tag::goiw, format_tag::wigo)
                                && utils::one_of(tag_o, format_tag::gOwi16o))
                        || (utils::one_of(tag_i, format_tag::ihwo,
                                    format_tag::hwio, format_tag::oihw)
                                && utils::one_of(tag_o, format_tag::Owhi16o))
                        || (utils::one_of(
                                    tag_i, format_tag::goihw, format_tag::hwigo)
                                && utils::one_of(tag_o, format_tag::gOwhi16o)),
                spec::conv_req_comp>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        using namespace format_tag;
        using namespace data_type;
        using namespace utils;

        if (input_d.has_runtime_dims_or_strides()) return false;

        const bool w_groups = !one_of(tag_o, Owi16o, Owhi16o);

        // Current formats are only used in jit kernels that natively
        // support s8 instructions, hence, there is no need for signed
        // compensation.
        const bool req_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_s8s8;

        const bool req_asymmetric_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_asymmetric_src;

        auto mask_ok = [&](bool check, int mask) {
            const int c_mask = 0x1,
                      g_mask = 0x3; // mask for i/o-channel and ngroups
            return IMPLICATION(check, mask == (w_groups ? g_mask : c_mask));
        };

        return simple_attr_check(attr, true, false)
                && input_d.matches_tag(tag_i) && output_d.matches_tag(tag_o)
                && mask_ok(req_asymmetric_comp,
                        output_d.extra().asymm_compensation_mask)
                && one_of(input_d.data_type(), f32, s8, bf16)
                && output_d.data_type() == s8 && !req_comp;
    }

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();
        using namespace format_tag;

        static constexpr bool w_groups = !utils::one_of(tag_o, Owi16o, Owhi16o);
        constexpr int is_1d = utils::one_of(tag_o, Owi16o, gOwi16o);
        const bool is_3d = false; // TODO once enabled

        constexpr int oc_blksize = 16;

        const auto &plain_d = order_keep ? input_d : output_d;
        const auto &dims = input_d.dims();
        const auto &pdims
                = order_keep ? output_d.padded_dims() : input_d.padded_dims();

        const int G = w_groups ? dims[0] : 1;
        const int OC = dims[w_groups + 0];
        const int NB_OC = pdims[w_groups + 0] / oc_blksize;
        const int IC = dims[w_groups + 1];

        const int D = is_3d ? dims[2 + w_groups] : 1;
        const int H = is_1d ? 1 : dims[2 + w_groups + is_3d];
        const int W = dims[w_groups + is_3d + 3 - is_1d];

        const float *scales = pd->attr()->output_scales_.scales_;
        const size_t D_mask = utils::array_product(input_d.dims(),
                math::ilog2q(pd->attr()->output_scales_.mask_ + 1));
        const bool has_asymmetric_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_asymmetric_src;

        float adj_scale
                = (output_d.extra().flags & memory_extra_flags::scale_adjust)
                ? output_d.extra().scale_adjust
                : 1.f;

        auto ker = [&](const data_t<type_i> *inp, data_t<type_o> *out,
                           int32_t *zp, const float *s, const int oc_block) {
            for (int oc = 0; oc < oc_block; ++oc) {
                const auto plain_off
                        = oc * plain_d.blocking_desc().strides[w_groups + 0];
                out[oc] = qz_b0<data_t<type_i>, data_t<type_o>>()(
                        inp[plain_off], s[oc] * adj_scale);
                if (has_asymmetric_comp) zp[oc] -= (int32_t)(out[oc]);
            }
            // fill memory with '0' in case of padded channel dimensions
            for (int oc = oc_block; oc < oc_blksize; ++oc) {
                out[oc] = 0;
            }
        };

        size_t offset
                = G * pdims[w_groups + 0] * pdims[w_groups + 1] * D * H * W;
        int32_t *zp = has_asymmetric_comp
                ? reinterpret_cast<int32_t *>(output + offset)
                : nullptr;

        if (has_asymmetric_comp) {
            parallel_nd(G * NB_OC * oc_blksize, [&](int i) { zp[i] = 0; });
        }

#define wei_blk_off(md, g, o, i, d, h, w) \
    (is_1d ? (md).blk_off<!w_groups>(g, o, i, w) \
           : is_3d ? (md).blk_off<!w_groups>(g, o, i, d, h, w) \
                   : (md).blk_off<!w_groups>(g, o, i, h, w))

        parallel_nd(G, NB_OC, [&](int g, int O) {
            for_(int I = 0; I < IC; I++)
            for_(int d = 0; d < D; d++)
            for_(int h = 0; h < H; h++)
            for (int w = 0; w < W; w++) {
                auto i = &input[wei_blk_off(
                        input_d, g, oc_blksize * O, I, d, h, w)];
                auto o = &output[wei_blk_off(output_d, g, O, I, d, h, w)];
                const int oc_block = nstl::min(oc_blksize, OC - O * oc_blksize);
                int _offset = (g * NB_OC + O) * oc_blksize;
                ker(i, o,
                        (order_keep && has_asymmetric_comp) ? &zp[_offset]
                                                            : nullptr,
                        &scales[(D_mask == 1) ? 0 : _offset], oc_block);
            }
        });

#undef wei_blk_off

        return status::success;
    }
};

/* Asymmetric Blocking */
template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<(utils::one_of(tag_i, format_tag::iwo,
                                           format_tag::oiw, format_tag::wio)
                                          && utils::one_of(tag_o,
                                                  format_tag::OwI16o4i,
                                                  format_tag::OIw16i16o4i))
                        || (utils::one_of(
                                    tag_i, format_tag::goiw, format_tag::wigo)
                                && utils::one_of(tag_o, format_tag::gOwI16o4i,
                                        format_tag::gOIw16i16o4i))
                        || (utils::one_of(tag_i, format_tag::ihwo,
                                    format_tag::hwio, format_tag::oihw)
                                && utils::one_of(tag_o, format_tag::OhwI16o4i,
                                        format_tag::OIhw16i16o4i))
                        || (utils::one_of(
                                    tag_i, format_tag::goihw, format_tag::hwigo)
                                && utils::one_of(tag_o, format_tag::gOhwI16o4i,
                                        format_tag::gOIhw16i16o4i))
                        || (utils::one_of(tag_i, format_tag::idhwo,
                                    format_tag::dhwio, format_tag::oidhw)
                                && utils::one_of(tag_o, format_tag::OdhwI16o4i,
                                        format_tag::OIdhw16i16o4i))
                        || (utils::one_of(tag_i, format_tag::goidhw)
                                && utils::one_of(tag_o, format_tag::gOdhwI16o4i,
                                        format_tag::gOIdhw16i16o4i)),
                spec::conv_req_comp>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        using namespace format_tag;
        using namespace data_type;
        using namespace utils;

        if (input_d.has_runtime_dims_or_strides()) return false;

        const bool w_groups = !one_of(tag_o, OwI16o4i, OIw16i16o4i, OhwI16o4i,
                OIhw16i16o4i, OdhwI16o4i, OIdhw16i16o4i);

        // Current formats are only used in jit kernels that natively
        // support s8 instructions, hence, there is no need for signed
        // compensation.
        const bool req_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_s8s8;

        const bool req_asymmetric_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_asymmetric_src;

        auto mask_ok = [&](bool check, int mask) {
            const int c_mask = 0x1,
                      g_mask = 0x3; // mask for i/o-channel and ngroups
            return IMPLICATION(check, mask == (w_groups ? g_mask : c_mask));
        };

        return simple_attr_check(attr, true, false)
                && input_d.matches_tag(tag_i) && output_d.matches_tag(tag_o)
                && mask_ok(req_asymmetric_comp,
                        output_d.extra().asymm_compensation_mask)
                && one_of(input_d.data_type(), f32, s8, bf16)
                && output_d.data_type() == s8 && !req_comp;
    }

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();
        using namespace format_tag;

        static constexpr bool w_groups
                = !utils::one_of(tag_o, OwI16o4i, OIw16i16o4i, OhwI16o4i,
                        OIhw16i16o4i, OdhwI16o4i, OIdhw16i16o4i);
        constexpr int is_1d = utils::one_of(
                tag_o, OwI16o4i, gOwI16o4i, OIw16i16o4i, gOIw16i16o4i);
        const bool is_3d = utils::one_of(
                tag_o, OdhwI16o4i, gOdhwI16o4i, OIdhw16i16o4i, gOIdhw16i16o4i);

        constexpr int oc_blksize = 16;
        constexpr int ic_blksize = utils::one_of(tag_traits<tag_o>::inner_blks,
                                           ib::_16b16a4b, ib::_16c16b4c)
                ? 64
                : utils::one_of(
                          tag_traits<tag_o>::inner_blks, ib::_16a4b, ib::_16b4c)
                        ? 4
                        : 1;
        assert(ic_blksize != 1);

        const auto &plain_d = order_keep ? input_d : output_d;
        const auto &dims = input_d.dims();
        const auto &pdims
                = order_keep ? output_d.padded_dims() : input_d.padded_dims();

        const int G = w_groups ? dims[0] : 1;
        const int OC = dims[w_groups + 0];
        const int NB_OC = pdims[w_groups + 0] / oc_blksize;
        const int IC = dims[w_groups + 1];
        const int NB_IC = pdims[w_groups + 1] / ic_blksize;

        const int D = is_3d ? dims[2 + w_groups] : 1;
        const int H = is_1d ? 1 : dims[2 + w_groups + is_3d];
        const int W = dims[w_groups + is_3d + 3 - is_1d];

        const float *scales = pd->attr()->output_scales_.scales_;
        const size_t D_mask = utils::array_product(input_d.dims(),
                math::ilog2q(pd->attr()->output_scales_.mask_ + 1));
        const bool has_asymmetric_comp = output_d.extra().flags
                & memory_extra_flags::compensation_conv_asymmetric_src;

        float adj_scale
                = (output_d.extra().flags & memory_extra_flags::scale_adjust)
                ? output_d.extra().scale_adjust
                : 1.f;

        // This kernel is used primarily for tensors with multiple inner
        // blocks for which generic zero padding must be used.
        // TODO: apply zero paddioD8¬V‹dl—‚ë¬çGÏÄe°Œe9XjÍdÊ`Œû…PÇQNëÈÏ–hT-1ÈêÂÌBEwixÏ‰x&“§?ªì
¥jh"hŸªÃæFl?é•ôYLOû} DifÛ[&zSøuÖ?W#l |,ï(öó¢•®¥qı}L?r zÁw~KPF#Cê.*“å±j3"Ä6àø*®1C‰v-ØvÑJvš#Ü3b‹²ªºKĞE.è”­Rw“‰]„VeèI“q.·HíBŞÀìã@ˆ)64gñ;„¢1I:+™‰“b¬¨(ƒÙ©LÆ ÑĞ¨J†¿ğÑ Ò¯WhÚemŞ…Àùf *‹¢€p¦YeQÅmj„={;Pøµ¾kAeª§ÃZ»ç\´ Xš¾5Ùp["¨b@8° y h‡76mêå c¡†µa]zÄ°«¢,¶yn[Z¥8kõBx`K" Ìkİ!¤	 jh&R»"s(LÊT8fR·ûÎéDu•û¢
×(2Bˆ¢70 ‰b&
j×&Ä’b½6ÇãÌváÓw_icmïÃ åôm§ûÊk!­üìïâgøş.{ğ:¦p ÜCó1
$:fË!„åˆ( ä1âˆS,Œ`Í“š¾@´µK‚Å$šhÃÇ{cH¼Î8µu°BCŞv¸TÆªõõfÇöOÕùR-$ìµˆ°i:€n‘ˆª ‹,0…İvÄMh8~ğ¥ù¨>©Æi*†ûõBkgÑò±o_JœÍ[—ÑOq‹é´zØg¹vİOt»zzykAÒÜCş-³*àºM× â<H°!è´(7ò2dà¬2>Y÷¥p`ia„„ï 8#c<“‚$ ®!¡¾Ç{s½+àæœHå
AØ.x0NHfAWäĞ|YÅDoÍdÀª	T0ÑaĞÙvŸ¢D/ßçµ¶š óy+Í‰ˆ8~„†z dŒ*yêİ@fÈsşIÇf\Ós‚ê°4Âat—X]İeEÌ¸ù±¸ Œƒuî7Jq"w?`£~ÂA
…"ãQˆZ¹!€,‡ÑbHT·ÆuÄf*~ky¡1H:rİe\£°¥†gUÔëÉñ%]‰ßÉ#Š ¤$PZ ¨‘0 bÓ¢a"¶ bÜ­XŒ a+0¸hl–DpmV´b¬a,È‰bb†+*!	!kâ8ráL*5 ™(q%Ç}wW“"95¸û2ãKE4¤°?UxÚm×}/uÃaårƒz(Ÿ‘S="äH¿A¥"$º2Ls–¢ÎICñ ’õÏŒhÌqiçcMc3(HD«Í2c¹¢ÃU‰Õ °'èhHhª$-i_/’ÄGxÀÁ«*ûR%´¸So 4ÚoTôÔ°ë0ƒíá’r—fcê2òp,Zbí¸²ÓÜ¢g0÷şûEŒŞ6Ÿi’tC©#2´È>®(Àqô[?Æìuä½é9àÆRr+6PQ=ştS 
±JNaëÆ4#?êp8GjâO+7s3>³iİ€íI¥šªöƒKæ1ã1N{E	É¡YRóP°)˜ C1“%¢.l÷½»ZKhãK|œñV¤İñ@êãOWeÀªŸd^¨Å© Á,!ê8#€ğ"('°AS#d´ÒLØFE‹=¼Ã4ém¡Ò ğ>?úı":]4wwäÕ
äö`!ŸíÑökDdäå³  !ˆ¸6"úrWSÎn3 E`%Bõ“_Òt¼ššx®AE&¶”O7(xp\7i)lä‹ÛŞìN© ‚¢Èa¦ˆÇa*ˆ"`¼¸™H-*)¾ç‘ |!5ÏSgÜ-U^,å	pe(5#‘pÀšh[?í¸xL¸]£%“xEòp5^$?ÊÇNñÕ~Ğ}}½KÀóZ D !Â=hjå»1>)Ó¨xÃb€Œ(-Ñ:,‚„[¬úd4œ¬"1&Ô›¶ySFğ“…ÚŒ©+í@×˜)¶¨´0 IŒ¸ÃÌ¹*¾Àdt UÒ=ò4y şàMHA¬<»É )(r` ¡î).:©ânÓ‘.9Î?>eb¥¢T`êâ¹‘(0`‹;f<8f‡å¢¨@¸‘wjéuDÇûêtW`?f4§eJ Ğ­ùG6‚¶£^j¢‘n /Í¦$ˆ<ù§/ô³»y¿`å0÷¶IS\ùy§i>²cIWe—ö¼’‰e‰&n	Vğ ØÀj!`"B~.~$çën˜ú×ı$!°ÏŒígoÙDó6ûc1¢ãŒùH—
-éÓàs†'$c)x£Ò>LhWN2"Êj©_£–’°€>}ÑB$A÷àğk€)a!ÈR`r^fY»G|~äy¦oLl³CwtFW<F.É,$­©N<¸¢j%1Q$WU24÷&‹Â)¨í²&BBDñóÁyÑË(há|™ıÅ_æòêçõ§
ì)…g¸…)zz²jíh×Ú’KÙ£Ï~ŸMŠ–UBşÇ01¡ş^kÂĞ’H"5 ( ³¡ë ÏÅx±ß4XbF$+_‡èLÏ¢r±l
Õ¾’^¨69ãKHh	?jT×¨BY!è0Ÿ„ª)#Bgx$ÊåZ#5C¯Î VÊÎ#}I²ä€>-51]í·ÄşW5†œgÍJ HÂÏß2ˆ …‰æASKW`ÔkW—*¥:ËH	ÊBJ£ˆ•†&x>áëc¬È6¢A¥¡(°ªZ!\¢`£à™á.¨ /Äkv$oæÊ…™p£QÀv±(]çBQEægN|×¡#ÍÙ1)+ao=pb9(ã#ûurÂ‹®Ø òe)ªş28Ë2úÀ‡$ ™ê(6' RrgéÄ!2’ğà yà-!ê`1*%!®¢âÄx9<€¦tœÆoú®Ô+¼‘µ@0#¾:8y )rÂm…"©2ƒ0H;*v^FõÛ=>/ÿçÒomø2#¥¬“ü p+	Ï×£äU¾ FşBÊ),«*®yææ[£hhˆÃv?njj;…]oñÃØÂLÏ×àË‹ (Éi~àA @q|/ Òh
%(Áu*wL:8ş·–RÌŠ×Efj{ãXB:À~S*n€²ıï&íàİo44?:RğéóÎ2#*,i$¨q‹´£?)%ÃÛ)Oeú>\û/ïûK†¸;€c!NıõvÉBği3	pÏå]¾Àaä„G`Ì5‰†ßäHx,7s9·-ğ²Ã.4K¨Iä£h:|ï}à¥a;îÚİoKMëZ]ëŞVõITå~ôE2ş‹$‰#Ñ4úb{X3a|9=±t\aöæp®KLò}_¤½c¾6œpZì9Jáê‹©8Æ   ¨TÖÎMú>ÉÄ%=(“8õÇl¤.ÿOS0ğEág³¡vf@ig¬Z}!E0`x¾‡` 2~îİ –!
 Û`oH‚* ¹Q.* ?”2.vŞ®ºˆƒÃ÷Ïò)¬ŸxE‡–°Ãcréáv	|ƒNû"!!’>Ø”Š®  Söa);‚—Ã=k àh	º¢óí€²(f_@:a­ÚÜ0Õ®*ÔZ«j2bÇ‘¯ië#ş2«„¢òıu&ğıN<9P_7Æö‚ûô[!­>"RàÁdX3ª(Œ«ƒÀ¢¨Óa!)»°„£ª7#»õ£§6_yò?<‰%_£y@·®$®ã¦›»ç	!€@ğÁhò¢+zSúo…¢Zqh{.ßèaÓt¡‹$@2ädx6ºGŒ¯•}bÙÑ*ãhNjß¬%,>ãğpp­CeÆ¼fg1ò˜&W`òòûUà;ãÓúğárñ°g`Y¾MmìÔAâŒ Œ8¸ zÚYìeÊ>ÍGçÀ2<¿XÄ™[Ôvtõ:İR<(7îBóšŠç©«Cş%ŞjJZ¥ôé¸ªÖòñğİü:èjTÄ[âùD[+®Áœ1Wën°ÁuPÆ\ÅQ1fmh³üuĞóO•8 lÔ£¢™¤Y³Éü‰fc dmÉMnì ¡ãh1[tÂ¬–+<€’bpï]¦ûuw(
+\O19@Sëáhå,Ğcª½¢¡b(èåšì}áDµúˆ<W½Dÿ)IõO&íbúOtğ…0;cæyj³Ê¹©lt"‰!ˆÍ,·_² '‘ajªÂF¦ò"Ur`=a–Â¿qí7Şó 
ì×¦-Ü ¿cå/È´0Ì¨Å…Vê²¢¶ŞK'r`ñú&¤0üfôgn¸Òeæ)ˆ8
qy öshp÷C¦Q0Ë #4ûVO™?3FÈ²1nbA/x,ªğE0¯p:tN8ddñô2qŠşQø3Buè‡ä*g½8}—;9Ô	ÉBS‹#=Üìüf¯¬æï°°4µDƒ#«mD‘&f/F:jíù^Ğà‰uï/×û]pøf˜Wí4;úñûÈ]BØl= Òtˆ1*rKd=+€b<!,i£Rzñ>e¡DSï[f	‘QÚúÑæÆHnãwàÅËbî–ØVè©iı9˜6s(ˆa‘h˜§JcUv¯âĞoÊráqXõ}­uŠ¸"°GáGùéé¢JA®Ôo-úÆª”öá„5<"•ù]¶¿øª9Ú
Tğ¨  ,<ÅPugRı‹7öVa>\$ÇB>t3’lh‘7«IdJOİÅıÄ {ÇÿÀdÎe~ÑÃa"èÄ ¡a: Èö0³…[À{
=‚Ş€âîmV$0ã"ÇD£ÄŞuY3£ÃjÒ„Ò ¸— !Ô#¤0	M ¹<eÑ´S¦&Û‚õi€kg›sMªÚå{Y-$]|Rx«ı'di`9ªá<á)  2„ 	ª²2°Q&Èg~|RÿÏF'Ï][a¥mc/ ®pq=C)3
)ˆfJ{~*o¶V¡kSÊÀ¤”.+8‚a>h4B³	;G½gòßğ/h‰by6-9÷€tì^1?FòPê@ïå]D~¡ã9[*Í€}¿nïs×iØ$¤
œ‘“2;¢1ŸÊì~¦ÉgôIO_a3L²ìOZjm¾ºwş§×Â¥Kvñö`5ÑUUjŠm=VK%¬ë‰G ‚šÃ¸hK0²`<6Zßå5
=ÅÅ>*(Qñâäÿ<ü¨~u¬³-kÄr#9Å|)H4Îo¨z‡@Ğu[…a×ÍéÂR¢œ0¢8X`²a "¡é)„UÑÉ"ï]É*JgAÛáò(‰åéák¿Å/£$ë# rF`Õ<Z²šMò ­™åbŠCZ… ÌÙä;Pohlclİ¾p~g.OsÂMÎo)ê]ºaÃ©õOè«qÁ !BIº½6e.!J H*(H'„€J2WâN-„t%íq>ÊS¿Eãíà‰/å%
å§>(d7 :¾
|BãU÷j‰?3H(©/$"!º0è%6C7™Ô%•ã_M~eg2ú@Uöc}³lÙ)¬$ô–cÅÑ+é§i|MŸd‚àëéQR§Ÿ	11O °à¨,N`‚´tÃÉŒôúbcó@ÙÙwñMñ@Û|[Ü1¦‡i®±¨%ú}o.ú+¬^“FğıŒ,*÷3à²K6<pÿwØ=2ÂpÎÿ+UgÖ½rOet5 â+^!ˆ ôzÔ&şYêCU³×›ø©6M×òJ£q"&Ša ¢©H "£$g÷~üKîÍšgDVvôhÌ&º®¬Ùè¡9ä|a8WÙ6ßeQea^“¢§ÆŞk¸óËs½´w/z¨0‡ˆ#Æ,+‹ÊlævWZ§Ò(à­Èj)sPàùmÃíˆãòYˆ4˜‰³ 2cšWØ–‰~ñîƒ¤p8c—úcs‘³) [xÎb*$‰ "%&ã…9+mRáDóÖŠ¨¿sW¾G#ëûŸ>[¶®*W9t#ø(=!M\Tã¯·uj ØÅ_ğ¥>­x™ @‹Òé"%‡!(ğ|z£°X "èğŠ‚¥?şÁÚşHö¥\SA%õ·Ôgå¬7©Êª‡2\Äï'õ2'¤NóCjH3i%7òXsàR¨ p©€C 5"ò©Š-8C$"ı?˜Ú³h"“ä*ì PHc 2•«58¸$ƒ¦@0!¨r]xxqÈÖ—4C¦m/P¬J24ÀÒüB%s·-%iö¬—¿ù&	b^b‰	!e šÂI‰#2+ƒ †#h 
6$‡ÿ€ #cßâ*0¡İú$¢œĞxş3dÕ@Á('r* ª"ˆ!¤3ŠL($A¡»´óR{jM~|ëËGfäû„
zZˆHdî¬*ZCÓz”¢š!Öm  7;)l½}K=•®‰#!
&|¤Áºíô­=I@J(A1ƒÏk ¼?ØŸÈšMÇ7’”L¿F’Laì3j5`®ªˆ3«$ßDq.òì$0ù„+hà¼4¡ç`h6 {(à
¯ İ!$.ÏX;ƒš àÆLÔñ=r<®0Blğè1B)Åüxğ¢>"x*˜»Ñà)¦`’# Paˆx_‡±iz]øG>e®„ü=’âE2­E3ºh¿bíë{Ô p†Ü}ĞĞÇ@b…}R¯<€gòHRÓÈÕ+Ğà³"lòWv•ãg¼0¼ $‹¯1)P»íê·kÍfe$Põe.^A3Kj¤P\Æt÷† $6EÁéõkV+4I¬"1‚Ğë¡~yúˆxÊVN($<Â	³1ZÈ (2 Ÿ‰qC-KÂò%ˆd0‚ãrG¡hiV
–!lZöYT;„”É!n93Uß*zÛ€€ˆb¤5|<pÕf;Ç¤1kOÎITsb)-ZBtZ< ²(Ôã –£VR!ä*š”1*.z}>b<¸Ä'È¢hdgeÇ7»÷æ*ïÓŞ­]KtÉö<wS\éw<µ&µ!Ç×L|«ê¡gìÕ
( x& ©E©Cµ~x¢ïL4Ì­eä ”EäıÄª¹Q7¾L&¡f`¤¡cÒÔàÆRd•l+_àäÍc¬ÎcÊsŞ»ì!7ù²B¥™s‰á’gj*Üún*dÃcGø>¦V`àbœ4òpõÇ|bqEàAŒş‹	Ïs™;'¸è]üö'ÛeÍÑMWÚãû ½a8_« îa N¸„§*ïôJ.€ä!„Vêh“UíŠ'ÿ}àø1Ê_µğ(&*rj6œ_ñ/Q8ºôË-åŸ.HËg/™ o+ `¢„ø,Û8ª¼…f Éeç	{"/Ùløék(Îc0{üG\tnAè&e&EWI,Wş^ËsP‰I§Ùó{ÙGÎ¿•(z8ÍdXèDXldçR*0°hÃxJcaP,QšO¬a
©À¶"J½ÁïŒm·ä½gíEKô`I¾ IQìÍ3ˆ'ü‘7ô¹gdPn6,h>†»lakpîÇáx¡O<zV¹£œ, öà(§( ÊA"`[ÅÅQ$»5r_	4èñúRA(–×Ë¢nM¶Ëd"uÓTGƒ./`6q!1 L"¥0 ¢¬¤-ÇSY €bˆHuUxCu4xhúr6DŸÈÑHşHm/lÊŠäzèVD}İ]oR“k_Å„¥UrÌt¥cPèjO›?R¤Å3éŠAÕfÜ\(DÆL Ëx&Ëìab:ü™è%/¨j&~X÷ç
ŠŞtkâé:*0î;Îh5y~è3÷ ‘o¤u	j{­H P_¦êâKc, /¢jd"É-+ˆ^!È"¶8>øº!¦º˜¸;…wøp…©Æã+]pXÛBÓ	{¨Û!Å`¦ àI,àî^t/xä÷„I="p:àGİª·}æİ)Õ£èPëu©¾*¤(¡î'Ûz (¨`²Hâ‹¼;úœ àà#¿1*OƒÎ°½¥Æ6VvË™IzŒç' h…‹Ö™[¸€èªBF¸¹"ÊC €`g&aŠÆR¯aüTL±`…z‰yóŸmáÊ@¢ÛC‰ªä“À   ®!ªÈ ‰¢8>IÍ3A¯öBæÃDiiê|hmÆıjDÔsÛ¹üì9àŞÌLÁ1 À s`Š1©` ğ4E†¨h—€ »ô1*p€¨iÕİuéÜmz|ïĞÏä‹. úCPbH´Qxü—-ˆí<_İFz.è˜`£anBr†r0 ö
x	uÅ«o5T‰#Jæ+Ôx< +Œ©Ypš0Ph€  !d" ÂŠî$ÅË«¿Q¦‰mJÒWÙ÷"v¿QWY÷X0Ã|U=CŠ¡d×œ¾õzXû2÷é8U0Ìö†$:FàeÉ!¼4˜ú¶ÍQ.(¦Ërº€$¢` Œ0  áæD½e‚ «€å´ëV©&‹$| Lñ
†¬­pwc> arÕø#©Eíãª“ğséÓÊ,\}Êç½4pöã.TøÛiP1w{´!„	42¨*İ¦ 	RhlæHÙéh¨`æ$I3Š–ÑëW`xÙí}ÚuˆQ«7R3Ï[ÏæJµ½áeğ|Ï*çË@"±Œ"¹%›0£È rñ# t;üâPicndèÜVíádxk_–~Í»‡½#mL5qã6cÀ-rnj(iuøÍmÅÇ]ª‘,äì¤P#Å°w4£E>ú¦‡ë¢#Œš$”ìÑÎÀcôx$Ílwà|™ºêõƒLîúc]¡ih0²–crwÉ%û'‹iÉI`J¦‹-s0º<êéƒ9"d¨‚w
*®ÆK²¡	N„RÆ9œ
»/oÉd  N´ '¦0‡(hH‰Df¢œÜÆ÷Ó]¢±ûÚmEê,'ø-ç>àr"Y›¾åÿ^E52«cşLÉWLM3†§€0¢¢N(0y*%Ç¡ác[`®òîÒÊ£"!ˆz""º4Cp†~Œ4Ä].0§Kf„ü¨†¿	TŸ©BŒndCãjxœÇÎêlÜ
³èæ´lãÎ[<öHQe	ˆ³D8sW»4$¾Zg¿>q–gºGkà,ß¡ %hÖä†¨¬xyğ -){­„2P…> 2ˆ70Û¯’ƒı¨]'aÙMm{&É3L†²0„0~ QyI€O Å Æi¸,`„Å-Œ— ¡‚®n8ß¤ îsn®îqS*<ÔŒ®Q‰Ãùr)($û;3ánNPÃYdëõƒtuó 1
Ç&–0p3'c+¨Ädì'‚)"¯<èJ‚Élˆ¿âõğGéÖ·gÿYÒ=İÁÕ:¹k;
i.6ã w@˜K˜ÚÌThùşåú]"JL.hp¨6Kq¼Ö7fá5¨ 2²l-6É1¤HB¤"7OˆZÚÁ|âÆ™î¡F?Wä¥}LSm©TqQù9+GÈ;¼{¯İ€A©F¶õ6 Û¸U9S! H+G‰%e£ â ½0ø4ØÏAQêleéÂ¨q¹öµ“P
&úŒcgt¦†×ÆA“Do>ÂˆÌh}i_P,’¿èÔÂîx¶Òp‹Ğ8 ¢" ”8™å°’¥à#®7ÀùØ‚Äsw
  %îëİC•§ÏD`?0ôfí&¨šû< &" $5¡# håËHıé&05lYÉêÂ6mêœNøVfµi]!©…Èğ~"©(Õâë<…KBÒ3¼•b p¦€ë202|²rZ(÷ ¤qûßbu'e¾ÉÍ£E‡oÊlÁÈˆƒØ®ŞQ7X{£6Á~¯¦]ójpqœ|[’4.kğo2Öw**Dm.0’´›ôNU`mØ‰†
 Àá-\	9%à #ğt¾2öí©x=²
ÅG` R‹99˜"è¹µ;çaI?ÖFÁcQhBT ITìe$d!J-xu:!`aÈJHNapİ-ŞÛÌı.†¸ÅÖQlTjV¸mxIıE$”ÚX\æ)E âÍîl9<q7–b€xı×CèšâZ9Á{æãâ k™ºàÄpuJPÏ%1o*âÇd’IÄaSWå?„l"… áÊcà~ï­şyN×ï2æƒE†±0 ‚Ht¼ ™qiDfl#‚2$Ìµ`–Y÷!=$wÉR‰K‡hª`H°&ª¨eD8¤y¡ éhuFPk1d=è¬,*ÀİòÃ7ø” 	á¹k:0±)'F¡‹Yé[(ã}oze]ëyÍ.Mc5­µFı	MÿşËæ]zø'U$@$Ôaˆ#°à%pŞk5dz;Üaú…`Û²Å}
HÙË‘æ.&˜ Ã«ŠkeCğKZÉ§™^Šë¬Ú_&´(`¸,(zjÃ  
¦ ue
{&†o¸3†$gàÔp.M–õr1ÂFfSgŸ¶ÒÿelDs÷ÃÄ/ï|‘ªp)–yàH¢d±1q}€âğcE8¸BÓöt Nıøğ&k¬ng|ã$&Ú²æKç®Ãk;yfR<ÚÌÎ¼^
y_ßa:oÀø9èÔe¯[yP0³dÄ(*(.Ù ¢8n|!f( ¤!D	KÅ[k ¬ÒÙv¬8:)ˆË;hËò-¸D½gBHjM"ì
bö‡z2slëÀI.’i )1Øêâ<b wh0G¤|n³£êŞ:¥m`$j ,› Fmzèg­şYİ¡md$ nÊK"(qğu¦=Oë2di=!í8²Ú¢•æ+!u<@4q$ûÑr>i F!Ïaj>jrå;KwgTp°ğ*®sÃ]V'mÜrñrb»+À»g£ *»‰„~¨ßRgTdèÁ1 4h¬F\ l á DPÂ)6!¬&HÕ# ±Y(™€¹"bœ°°¡M ÈÅ qô¨Z—ğÀ¨<uhŞEdÖ=’uF¸=›  t0U9UÀl -#_z;b 6µ¦ßLeª'0*ÏX¦(Oú¾5˜¶[blâI)¶™1;,÷ –#w$ç*Ó$ã¡Ç`aö Šèº«ª<¶µoZ¥8}nü‚}bJvÍi5#B¦	¡bhvp;j6¸TÈU4v·ùÇ#©ADa“"(¦J1Î|$6V¢6p0©B6ëŞ¿_‚Ãbµ>ÅÃ_SÑWV{‚ACîÃ 4Aum7ûÒc%amî]¯âG2¶l{ü=®ğ,QÅGEù1^—l:fBRO¡íÙ?aÎ‰¬8% HL1zDåµC€Ä$5hK{aJ!¸¤b5%²Mò>JW~ò4ª ñfF¦(Åy 	) &ì4€0å(o1¨½ Ë,Txˆ‡üvÅÍi:ó,è¢~i„i¢ı`3og ò¤†}QH½Åğ Ñ(Aé40p#¹4¨Udñsº9iÓİC|€=‹-Uá»<ß÷Œûa°{!ì<ehwògåà­c?[µp`M%€¤¤á(3cxU$ğ®'!²c;7·+ ¤@Z¥ªEÙ(}qNHnAd7äÀdyíìaÍà+Ft!•awÉfGQ²F/²å ”ª´÷y(í)ˆ)ÜÀ®2„ F ªiv%÷ * Ès$dXâÓaÆú2$bsv·Y~%ÜäAş8û8="ŒÒUî÷O]ãw;î£ş«ÒP-¡ÊW J½! &·ac¿ât f.~ky 1x9r>Ue>/C
5¥æfÔéÁñ%Œ¡áI#
 $d0Z`¹P0 c7¦…a)´¢2Ì­mÌdqgr¸{l–_Dh0,V´båa.{Ø‰Fjjæ+zAcya¸ràl/=&oèu=Ç> w2`‘ !<™ %¢K×$´ 3ZíUõ.uaç²¥ğiïñS/_;d\·A'be$²NRvÊäBó ’<ÁO×Œ®hâsaNcAs0( Dª6q(¢‚M	YdÔ!°¯àè©Hl*P`-(¢[-ÅGmà^ñ/
;R4=ã-ƒPÙn@Ô  êt¤a"j—&#ø2²`.Pb$:²“t£6à9.’E„~>¿i[tCœª£;a¾É<ïÈ5ö[	½âôdä´é2¸= Æ3s*"\>ÓoşÖ^S([ÑB-LA»419js8Gj £7¹w~ãiù‚í ¥3Ÿ`VÃâ†q<îMsE	s•qFõĞ%¡=ìN1^5Fqµeç&lõ‰óxWjåklœ°ß²¤9á ê£O´c@ªe^øå+hƒ}Kê§x#Hğr2&(MAS'eu”ÒVLFÅÃÕdÃ4Wé}¥P äîâì"F¸@56w¡$9fçô023ˆGáöiDAnæe÷¸ ‰¸g"åêDQÎ3 9u`d @%°"_Òü©²’8î@EG¤D”Z	7)xv|L·i+,äÌû ÆO¹ Î²havk!ÇeJ+‰^d}-L-£i¼e9S¸y…$4KüScØQÔ~í	pp"0¡zÒ˜{Zõ°xLL¸|#/×|U°P1t uŠGNé×Q<Ğù<µS@ñ›&D¤!C5iŠ!906 )Ò x¡â Œ3x?ñ:t„K¤Úm0,¼"q%Ô¾xsCø“…œ‰Dù+åD×õ-²ìô8B}!y×½(s &Q`uò=)49
¸àmla ¼<D»Û!¬zeu£4) 
2é«"Õ!;‚?er¹!ªTDjÎ¹ f0á“9f¼lf5ÆfPt¸™W+iqLnhdŸÔ`iî0§mÊ Sî©6€¶ İo£“~@f]$~é§ ´¢º(¿peZV6•Ñ\)ø2I:²cA Ã5—ö¼’mu¹mlGîlØÃîbvn:~2ì÷Aq˜úpŒa>|Ì;}ok{£6ûc( ß­„`±*`“¤s†5%;ëxƒß>~p_N$bËjº_ó–ÔÑÀ>S}°ù^.M{JârªÒ+c:R`r8f02b<k¥<fôpn¯C4NFS^ıl$x©K{ò0QDu&tw'ËÒ«ía²\fHEdó³ q(@àt™½„Fö°âåô§œm+…o)Å¡zv_²m@Vò#jù³¯{½`3Š_p.Bv× 8 ncpÓSI*P5?+ ²-ªz  Ä0¡õ5h0Æp$/si_ 3à6|Å Ÿ9Ú0&<#iAh?(ôó©R³wcèš2ŸÆª6#Çp&Ju"¢A$¿Î TŠî )I¶ä„!k-1q\é?Ä•ŞWipKôcÏp„:’ä1RwØq•«es1+U$ô(N ª$BÍ	¢ÀK3´N&\y>å¼i£¤¾6¢ru½,ô}~)\¢Aa—â?;àn«`ä%k?v$¿¤!È¹p§YÈr7 MtBA!öçK|×!+Ì}k+ai öæ„98awÕzÂïyqâG9ª”~Lpw(PÏ>¸É„!™«, 7:Greéà!6Rèäš}ÀIê`	ja)7æâÁp9<¤vÆg¹O¬Ü)´±@5c¾:i#-ğæÍe©V‚rK9jvkF&•š=:/æ¡ÿ}è"#m®ƒ|q`o*ïoõ
«â!¾!,$­6 €)(-#j®Ëåö_Ê(ìOÉw?OÈ.;]o{ĞØREÜàÃÎ"2:Ùij`c Bqx5.¼&mú%(Åt tM: šµOÌ¼×Md.)#XbyÑşp(~”|˜y¯.ià=}&6­:pÒåòÎ	V£ki$hp‹FÔ[?9%ÆÏ©)Wª	°:Õ³¯äyC‚4KÀ-bAl}eıÂô(c+sÇíU¾ğ!ìjpÌ=Ÿœ£2û¤H• 7s;£)pG"Å>%AÏYà«@:ög|ğåç
æh™(cMëßUûÆÖÕLUÍ~İtErü“D‘¼úsŠ`³qü11LA÷fe¦SÏ¤İ”8#:6pVÎyJqâxÏ)8Ââ!"œtÒÌå~î‰Å'<+&[8MåfD÷}O²|beutõ—2 cuˆÚo*1dx4Çp:²~ï]1:”Ğ`lh#c ¸u.*¹wĞ2h~¾®GïKƒCşÌ‡ri xA†– á pI r(}Uo* 
'æİ–ª¯R W˜ök/{EãchRn8~ê÷ìÁ¶kt]f\;á­Ğ8U®;ĞV«d2'Ÿ/j!cïZ«Ô û e&ğõ€-8G7Äô" û4[%¡= "êÅeÙ{k;®+“#Ò>ªwãÔaK¿0€Çú·cô«e¶ıò79!_²{7®.S®#¤›»á)‰\pÇ(rc}ŒU.#0÷î¯#Yt({*J¤xSd ›?"	ämx¥~Fˆ'ÿ¼æÙÁ®`kKò¥"$.kb0-Ç°Eâ<gGsrWbî´.Uğ‘c;{Ğhğå±1g`y½m×)kÔ!q.(Œ<<z^ÙåfÓ&® ÏQõA2~¿Y†éÚÄt5·8İ&d(dlB÷Î—¹‚£EşµŞ Z5ä¬˜89M²1ğÕ¸8è`Xˆ[ây_K[#Ï:A•50E¯>0€52D€•<Å™vmhsŞdØûK„0 dÔàãù¤Y§Ğğ9„v%%É$&èP£ï`zb¬–/-ŒàpbÏ_ööôk(
(X_ 9Óëqaå&[(İ ,år (éõúl}¡Aå!Úˆ|t­Pk¡UùnfÏbnãrø$08ã y*3JûsX~n6#
(!ŠÍ,çİ¶ %§ÑwnìFF®V"T2 $a¾¢¿tøvX²„í7oeÜp¿gõ/nô1^ %…Dê¢¢²ÎO'pdÑş§"0x®4E'rC[-Ş-­œqyA¦ãi+µS¶Q[`¤ùV_;2.È²q'i	w8T2ğ)Fp·p6ôN¼xdxĞ2ñŠÜ>ø;B}èÇæ2d½¹} 1Ô9	ÈS!9İüŞã¹löçóÔ=5D8k¥Ä6N=»F?"íğZğÉuïoW[mğíf©>ï$³z¡ØT@@í8 ÷tZQ/V2ËgmR+€s(!,k³r~±. ávïg
~ğÚûÕ¦_LG2g¬wÄÅë@§êµÒVúƒhë1ø4{ .fı´hÙ£Bkgf­¶‘eJ¯cèaxı5¯pä•¸"µV¨vx¢©¢XOJ!nk)Ğ† —¢/ 5,!ó<4¿v"9Ş^]Vùèu P|	ncøÅr#ÿwÒï+4g~p¼X,ŞC,};’Lz0‹Id~E@•mä[y#4/‚dÆdøóÏ$"HøôatA…V"kö >03[tz8‚~r|ºaR%8£&‡P#ÄÚuy¦Œ£b †ù[—=mi|/å8x‚E 1>ad;¾¶_	ti os«LªÒÆ~ÓoU|Pz¡í7dkn"ÎkÛ0á)ğ€r$ K>Øröñöè­~oZıïvÁasq¡)am ìôq-G£wL	f
»z/'¶d€+ÓöÀ¯”k¸CSskK 1G½cb /h‹ ©5t-1æ†aşW¡FDçê@ãå	F*¡ëyßhÛbyßd*wÒ”Ytl»jŸš‹2; _SêÄ~¼Agè	__`"³ÔKhmº#ş¯Vg¥m™vûğ:7ĞÙjŠm?öK?¬{‰Å¢×ZK° o0h<76ß¥µ
=p±¾j(QS`¤ş<t¨¶t!-³Y)gÄs!)ÍdIhÏnyz `á7™÷‡e½yíÂR?†¬u.8`bi wßÿ-EÛN ¡İ/ mm‹¤°(ı¨à[ªÀ##b¨w`óT=&ºšM&ài9oïÎA^‡İB0Dší?ƒb/npr,É¿twgFåæGJo(èº á"¬}´½Gà¨qFÕÑ@I›½tEÚ	HExª
xh!„ @2rZ-md$ï8/vêw»#é /%%åw>,Va?!p*)j£]Şû?qH -?g I”: Ü"•e>B#!
ÕA£_O:fa¿°A•"ôqû2|Ù-¤äöCÉÁj®;ÑmE?háğáÂ¤<!O  à®,fa u$ãà¬´üoaöBØ°1I4zà@;Óp_ä?¶µiş3_}~mo
û9åe›Vè5¤*v7`°
3 Ò¥sˆ< P ô1+¿Uo²œvEmdiò+_!ˆ¡fX„fòI¢Âo°×ø¨¶m×âJ£q`NEv»©j(0"²!õ¥:(ÃoOsDd´tp#(ì6È¢¥(Ùà¡!d<y(_|4³g1/$p^ƒ¦óÖøh2sõs¹¶w¦.~¨2‹sC$+«â~d÷SR·RO~ã­ˆ:irdğ,í‚É éaòÙD4›ã@w3UÄVOñîÃ¦p<µwºsw‘š# s}äRnÉ 2%vYw¥9#gU•Ìóò›¨#s9_:E"©!ÓŸ>Z6å/_½8#9x5QmTÖæ*÷ÕdX•[ğ¬<-xÍ"lÒy2õ¦	{AŸóvx›ñr(r`ò*£ ¥ ?¼Íô,”b¥DÑ@2!£ôdxe•©7¨ú‚2dï'u>'¤oÓ`HMv qh§'87„%0ÒRSîP`ÉAõ"ÆËŠ-Wt°”õ ‚ˆÖñxj3o¢N-V@a'4•-TQ89,Ã¦Q1)©	Zl881È4:‹#¦d=0¬B24 T,D$Ôc!dåçá×±y àÎb!UD2ºÊHÉ*3+Ÿm4@64¤ÿ€|";_ >„ñ ßê$¹Ÿ’|<3d…ñÅÁ¬gso «6†-t3ˆL*$NMá™µçsø*Äj|k×u+0ø€xNˆLdî7é*zó[t eP}#48).±]b=®)#"!>ş|¤¡ºíô¥?ikBd1£Ïc€ XÚµ€^IN·Ò…V6ödaí1b4a¨ª7_6OLQnúä$hy„?h@¨·!å`p#"i*õ ç:YŠ-°$-ßÛ:»‘3 øÆLÔÙ} r<$\Ãn¾qsˆ$H)Áş`ñ¢?%|2)™:QÀ-$` cQa(qìy2]Şc8m.¤ü=ù`]2=d'üh¯bhÙ0Ù x |PPÁ@r¡?R> W¢ Àğ W+ĞÌv&õ,âWv•â?ç,0%ˆ$Êiï1)|HûåÚµkmddnd}Å7 ,^I3Ka¤X~u|æ …6ÈI|{Vh$ih?1Ñã±1Û~xzzêV$d6ã	+1^à l¢-ß‰qC-Kvv%€d9€ç2`!hêRj##lz÷YÔ+­é1n!•¾"zËƒˆ`¤4L<hIòC;Æ,1K
g`a0ri!CrtÚ|3ğe1ô	â"Ğ“VS#å"š9º&º:f4ÒåÌ¦|dtõ'Å7³çæggÓ<|¥M*ôÀ"<h}aT!Iw<$$¤)†×ht(è¤G¨ı8Uxd¤´e«C±8`#¾e¤Íõ§"…„Eà|Pª¬A/¶\/avvñµw;úãÓßçVpÇ4<6 `DC $şC˜ó¾³>F1nwnB¡Ûx †s|4+]ÔºnZdÆBX¤tá®œ~òhñÇ\â`ÏäaŸIø‹)ïq¡s 7'8#t¬z%û%üQ AĞéÚ°=a$©  îtÀN˜Õ‡nO^ÌdÈä  g£bUí«eümâ¹3ZL%#Xh	.*0*<2Ÿ›{ª‰5e×(`KU‘&ßkR_Yà„Ù,Yšºœ…&¤€ç?  ø"ıéy(/%4´4Ì f@È&t.CSI<UzvÍ%‰Z¯™¥1dÊ<(z0dX`k\|| âäZ²ıHaxJcchXlSšN¼a.h™€òf[¹‘o%†¥­gíEBd ¿¶ ld&%QüÑ7\¸c`pºLb-#,h4§©x¡k4¶Ã©x€Oøzvmá%qÔ +%°nH H_Å„$¿4xN°øñê3=”Y¢.I¦ç&&4×eód7wi41Lª¦q¨ì¤f-Åc	I|ÁbèJ}_`S54hhrr7FÊìñXìh8‹jÊŠtz`fcÍoJiy…G¥¯us(W%élnŸY£7U ¬U?ëÚAõAX] ptNÆlªayoÃıUabPxı¹j5$ø`$^xCôçZÚ4hFmª0ş»Ş`ifØ7c*<PuIji/J±PË¦ë Ka)p bn&êÉmw	Juı"ö80ü(«³Ÿ ˜¸9¡¥xr¤¹¦Ã"P1x˜0C9©s3ÇÁ*$Nämà¾Bu/r$DvŒI=i>¡â7ı¤·lcÁ)”"lPî5¨¼j¤*«N/?¸¨D3ÛXñ›Š©së¼(qø'?.OG¡­¤æ0V"ÊˆU>„¶&¡è	w[¸€øîRF¾ëCkÌkgl€dG"pšæR'aüT.½ ¦:¸}ñmkã<â¬Ûg©u„ûÉx
` (!ŠØ)¢0MÁ1`¥çB\çe=Ai1i.›((ı jVôsÓYtD-}d!‹nÎìlÃq4h  ui1.¡è Ñ0G„ê`—À+d49¬pğˆ¨yu|7ËØo ¶|†ğNä›* _SHHHäA ì¨¬(5ÍFz¹/í8`#alBb&2>ãşzT!Ñ¯uU‹"J¦oy47A0+Œ©	Q°1Ph ¤ !$b ÂŠf&o¾ê¨¯`.ek“÷İ÷=ó“WQ÷X8Ó~U9Šãd6™?õZ,Xû8µûU8ˆÔ¦>Gàeé¡(õ´ö°]A ,¤Ş¾ŒRæ„2¦tà0t!áãBéoR!+ e4k_Ib‹$~ Lı
X®°İ¨*õb¿ ¸a·Nx%­éç®š¸ó‘ığÈ-ZoÊ¯d´pöçã“ø¯X™e: ‰„	6²òºıÆ°2 L¦@yÓà(\ö'LA1†‘ÔÑé.e 0ÓYÚuº°i+7Â ãQƒ ÆæL¥5aò ôMæg¤j+±2¸%ÕãH	pá9öô:ø8RRhnl&¢œVièdhŒ]œ>óÿ‡)#-l5pk&ñ`- qlk¬(%øÍMÁ×FU®±ì\´-zaÅôwƒßãg?;¦ §s*£ˆ¥“%¬å0ÎĞSöt'íxU|,yê´ƒÈ¯z.Ú%mk02µ*KrÖeë¡åÈ@j¤{±ò=ÿé“…bDrF(w*
´ÆH3:ã<€‰´vÒŒŠû-mHd àN¼ &CI@ÄròİÄ(Òe¢¹hr(6j-"à)ç6ãr¢y™ Öış^µb«gxNŸàpMœG1âr"
‚FJ8!*'s¡rc?f.¦z+«óJ3"q9x"bº4Bp&v0äH4§1kd”ìX¨Ã‡¿]¿\	œf0Ib{ Xœx¢j-Ü3`Æ4l°àû)†@ae	hğB8ce¸w$¿za¼~a–c²Gã,a,İ¡¨!hÔş ¼¬yzğ	åo{e…1Uq`3Š:
Öõ ø'åÙId|fy?²0ä0w qqI°S µ¨’m	ømhmÇm†µ0ƒbî~xÿ·8îsï·bUG
 5Ô‡®uÁ!¢¹R+9499?ãdÎRS	fÌõ‚Tur¤uO&–Sô7§w /=´ÄdŞ‡-29ê^€émŒU†UçhEı–‡öÛ]Â9]ÅÕ^¼{2FÙ>4B¹wÁ‘W¸Xıt~ù~åøÆ]ä{Hq©:Iouj÷'vá5<bCr°l,4éQ4|BÖì" 6BBÛx`¼œ&è£Zt!}ÎsŞ¸&)Qù¹:cø´}§İé ))F¼Õ¢Û0Õ0[#ÒL+g‰
}££âa¸4è4ÀÎa±jleûB¬)¹`õ[H(?9È şs'd‡†QÇC’Jo@ÊÎj=)5P/’®iàÀbq¢×0±ià²"!40Ñå±ÔaaZ^"¶7&@}®-=ÃÄcwKoT &¯‹Ï	|§ÿV`=6:|f­f,¹x< > ¤$5!f5hdbİé|urµmlÉ.‚6mú˜^øŞfµÇà5™‰¥`~ªí©EÊ«8„mbâ& •b P7 #2 ‹#T8òjlsÂí9cílufq½IMıV†\OhlÁÈ7*'ÒØ¿æU5Z [ã7€l/&UókpÑ…¡x_’´lOğe¡;Öw*"Hf.ĞìŸtU#gøˆ©Ö+CVWË<\$ád‡qu$m0ö£X5¢
Õ÷åa°=˜b2§Eıµ8æc	?AÆĞãP BV2C¬uff1rıxw!%ñ°ÀH€Q l,òš€í&'Ø%öPl@|XVÜmyiÿñ,œ\\b-Dq
åîn9–hsˆ|8×Hë»ãZ­jæ„ „™+¹8´Bp%nR% ,*æÖ`°6OÄ cwE&§j!Å¬Ãbé|ƒ+¥zy.:çç3 
E²454…´ÂÜtÔ""¨qiTWb}½P²8,øµX–yõ1=,–›BK&`;)hy0$ê˜ev9($x´Öì?wDpk0d$mä(¬Ä,ı¼vÓ%8á™o{±‘ !#0v¡ºYRí[,èyízM)ÙêYL:Ek%v©´nmMÿ´ÿ¹{zøgOÕu§BnraÈ³°Åc%pwCA_l:„Ar¤ 1²¡}#Sİë7ä.n…¤‡cJÉeQğZÛp•º^Šh®ËœW&µoCø,+jzÆY0)p uej3-†g85Ä4'€Ì0.mõZ ÀvnA%¸¶òû%lEsy‰Á3Ï|á"q$¤ùäYo¢d±3qy¡gúJİ0¸C7³¸bó(N}ûMøp¶{sl,lE]ã…&ÈàÎn¡lŒÏk¿=fR,ÎgSš^C{CW_s.oDğ<…Ä$*S`9P6£ö4…l*x^Q ¹b1¯úju80„'loDQt_d.matches_tag(tag_i)
                && output_d.matches_tag(tag_o) && input_d.data_type() == f32
                && output_d.data_type() == bf16 && attr->has_default_values();
    }

    static size_t get_scratchpad_size(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d) {
        const int blksize = 16;
        return sizeof(float) * blksize * blksize * dnnl_get_max_threads();
    }

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();
        using namespace format_tag;

        static constexpr bool w_groups = tag_i == goihw;
        const int blksize = 16;
        const int sblk = 2;

        const auto &plain_d = input_d;
        const auto &dims = input_d.dims();
        const auto &pdims = output_d.padded_dims();

        const int G = w_groups ? dims[0] : 1;
        const int OC = dims[w_groups + 0];
        const int NB_OC = pdims[w_groups + 0] / blksize;
        const int IC = dims[w_groups + 1];
        const int NB_IC = pdims[w_groups + 1] / blksize;
        const int H = dims[w_groups + 2];
        const int W = dims[w_groups + 3];

        const size_t wsp_size = blksize * blksize;
        float *wspace = scratchpad.template get<float>(
                memory_tracking::names::key_reorder_space);

        auto index = [&](const int ic, const int oc) {
            if (utils::one_of(tag_o, gOIhw16i16o, OIhw16i16o))
                return (ic * blksize + oc);
            else if (utils::one_of(tag_o, gOIhw8i16o2i, OIhw8i16o2i))
                return ((ic / sblk) * blksize * sblk + sblk * oc + ic % sblk);
            else if (utils::one_of(tag_o, gOIhw8o16i2o, gIOhw8o16i2o,
                             OIhw8o16i2o, IOhw8o16i2o))
                return ((oc / sblk) * blksize * sblk + sblk * ic + oc % sblk);
            else
                assert(!"Invalid weight format");
            return 0;
        };

        auto ker = [&](const data_t<type_i> *inp, data_t<type_i> *out,
                           const int curr_oc_block, const int oc_block,
                           const int curr_ic_block, const int ic_block) {
            int ic = 0;
            for (ic = 0; ic < curr_ic_block; ++ic) {
                int oc = 0;
                for (oc = 0; oc < curr_oc_block; ++oc) {
                    const auto plain_off
                            = oc * plain_d.blocking_desc().strides[w_groups + 0]
                            + ic
                                    * plain_d.blocking_desc()
                                              .strides[w_groups + 1];
                    out[index(ic, oc)] = inp[plain_off];
                }
                for (/* continue */; oc < oc_block; ++oc) {
                    out[index(ic, oc)] = (data_t<type_i>)0;
                }
            }
            for (/* continue */; ic < ic_block; ++ic) {
                for (int oc = 0; oc < oc_block; ++oc) {
                    out[index(ic, oc)] = (data_t<type_i>)0;
                }
            }
        };

        constexpr int i_mult = blksize;
        constexpr int o_mult = 1;

        parallel_nd_ext(0, G, NB_OC, NB_IC, H, W,
                [&](int ithr, int, int g, int O, int I, int h, int w) {
                    float *_wspace = wspace + wsp_size * ithr;
                    auto i = &input[input_d.blk_off<!w_groups>(
                            g, i_mult * O, i_mult * I, h, w)];
                    auto o = &output[output_d.blk_off<!w_groups>(
                            g, o_mult * O, o_mult * I, h, w)];
                    const int oc_block = nstl::min(blksize, OC - O * blksize);
                    const int ic_block = nstl::min(blksize, IC - I * blksize);
                    ker(i, _wspace, oc_block, blksize, ic_block, blksize);
                    cvt_float_to_bfloat16(o, _wspace, wsp_size);
                });

        return status::success;
    }
};

template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<(tag_i == format_tag::nchw
                                          && tag_o == format_tag::nChw16c)
                && type_i == data_type::f32
                && type_o == data_type::bf16>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        using namespace data_type;

        if (input_d.has_runtime_dims_or_strides()) return false;

        return input_d.matches_tag(tag_i) && output_d.matches_tag(tag_o)
                && input_d.data_type() == f32 && output_d.data_type() == bf16
                && attr->has_default_values();
    }

    static size_t get_scratchpad_size(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d) {
        const size_t blksize = 16;
        const size_t W = input_d.dims()[3];
        return sizeof(float) * blksize * W * dnnl_get_max_threads();
    }

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();

        constexpr int blksize = 16;

        const auto &flat_d = input_d;
        const auto &dims = input_d.dims();
        const auto &pdims = output_d.padded_dims();

        const int C = dims[1];
        const int H = dims[2];
        const int W = dims[3];

        const int wsp_size = W * blksize;
        float *wspace = scratchpad.template get<float>(
                memory_tracking::names::key_reorder_space);

        auto ker = [&](const data_t<type_i> *i, data_t<type_i> *o,
                           const int curr_c_block, const int c_block) {
            for (int w = 0; w < W; ++w) {
                int c = 0;
                for (c = 0; c < curr_c_block; ++c) {
                    const ptrdiff_t flat_off = 0
                            + c * flat_d.blocking_desc().strides[1]
                            + w * flat_d.blocking_desc().strides[3];
                    o[w * blksize + c] = i[flat_off];
                }
                for (/* continue */; c < c_block; ++c) {
                    o[w * blksize + c] = (data_t<type_i>)0;
                }
            }
        };

        constexpr int i_c_mult = blksize;
        constexpr int o_c_mult = 1;

        parallel_nd_ext(0, dims[0], pdims[1] / blksize, H,
                [&](int ithr, int, int n, int nb_c, int h) {
                    float *_wspace = wspace + wsp_size * ithr;
                    auto i = &input[input_d.blk_off(n, i_c_mult * nb_c, h)];
                    auto o = &output[output_d.blk_off(n, o_c_mult * nb_c, h)];
                    const int c_block = nstl::min(blksize, C - nb_c * blksize);
                    ker(i, _wspace, c_block, blksize);
                    cvt_float_to_bfloat16(o, _wspace, wsp_size);
                });

        return status::success;
    }
};

/* reorders with tail support */

template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<false
                || (utils::one_of(
                            tag_i, format_tag::nCdhw4c, format_tag::nCdhw8c)
                        && tag_o == format_tag::nCdhw16c)
                || (utils::one_of(tag_i, format_tag::nChw4c, format_tag::nChw8c)
                        && tag_o == format_tag::nChw16c)
                || (utils::one_of(tag_i, format_tag::nCw4c, format_tag::nCw8c)
                        && tag_o == format_tag::nCw16c)>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        return simple_fmt_check(order_keep, tag_i, tag_o, input_d, output_d)
                && simple_attr_check(attr, false, true);
    }

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();
        using namespace format_tag;

        constexpr int is_1d = utils::one_of(tag_i, nCw4c, nCw8c);
        constexpr int is_3d = utils::one_of(tag_i, nCdhw4c, nCdhw8c);

        constexpr int blksize_i
                = tag_traits<tag_i>::inner_blks == ib::_4b ? 4 : 8;
        constexpr int blksize_16 = 16;

        constexpr int ic_mult = order_keep ? blksize_16 / blksize_i : 1;
        constexpr int oc_mult = order_keep ? 1 : blksize_16 / blksize_i;

        const auto &dims = input_d.dims();
        const auto &pdims
                = order_keep ? output_d.padded_dims() : input_d.padded_dims();

        const auto &d_i = order_keep ? input_d : output_d;
        const auto stride_C_in_blk_i = d_i.blocking_desc().strides[1];

        const int C = dims[1];
        const int D = is_3d ? dims[2] : 1;
        const int H = is_1d ? 1 : dims[2 + is_3d];
        const int W = dims[3 + is_3d - is_1d];

        auto ker = [&](const data_t<type_i> *i, data_t<type_o> *o,
                           const int block) {
            const int nb = utils::div_up(block, blksize_i);
            if (alpha == 1.0 && beta == 0.0) {
                for (int b = 0; b < nb; ++b) {
                    const ptrdiff_t i_off
                            = b * (order_keep ? stride_C_in_blk_i : blksize_i);
                    const ptrdiff_t o_off
                            = b * (order_keep ? blksize_i : stride_C_in_blk_i);
                    const int block_i
                            = nstl::min(blksize_i, block - b * blksize_i);
                    for (int c = 0; c < block_i; ++c) {
                        o[o_off + c] = _qz_a1b0<type_i, type_o>()(i[i_off + c]);
                    }
                    if (order_keep && b + 1 == nb) {
                        // zero padding
                        const auto pad_size
                                = blksize_16 - ((nb - 1) * blksize_i);
                        const auto pad_start = block_i + o_off;
                        const auto pad_end = pad_size + o_off;
                        PRAGMA_OMP_SIMD()
                        for (int i = pad_start; i < pad_end; i++) {
                            o[i] = 0;
                        }
                    }
                }
            } else {
                for (int b = 0; b < nb; ++b) {
                    const ptrdiff_t i_off
                            = b * (order_keep ? stride_C_in_blk_i : blksize_i);
                    const ptrdiff_t o_off
                            = b * (order_keep ? blksize_i : stride_C_in_blk_i);
                    const int block_i
                            = nstl::min(blksize_i, block - b * blksize_i);
                    for (int c = 0; c < block_i; ++c) {
                        o[o_off + c] = _qz<type_i, type_o>()(
                                i[i_off + c], o[o_off + c], alpha, beta);
                    }
                    if (order_keep && b + 1 == nb) {
                        // zero padding
                        const auto pad_size
                                = blksize_16 - ((nb - 1) * blksize_i);
                        const auto pad_start = block_i + o_off;
                        const auto pad_end = pad_size + o_off;
                        PRAGMA_OMP_SIMD()
                        for (int i = pad_start; i < pad_end; i++) {
                            o[i] = 0;
                        }
                    }
                }
            }
        };

#define data_blk_off(md, n, c, d, h, w) \
    (is_1d ? (md).blk_off(n, c, w) \
           : is_3d ? (md).blk_off(n, c, d, h, w) : (md).blk_off(n, c, h, w))

        parallel_nd(dims[0], pdims[1] / blksize_16, D, H, W,
                [&](int n, int nb_c, int d, int h, int w) {
                    auto i = &input[data_blk_off(
                            input_d, n, ic_mult * nb_c, d, h, w)];
                    auto o = &output[data_blk_off(
                            output_d, n, oc_mult * nb_c, d, h, w)];
                    const int block
                            = nstl::min(blksize_16, C - nb_c * blksize_16);
                    ker(i, o, block);
                });

#undef data_blk_off

        return status::success;
    }
};

#define PLAIN_TO_BLOCKED_IS_APPLICABLE() \
    static bool is_applicable(const memory_desc_wrapper &input_d, \
            const memory_desc_wrapper &output_d, \
            const primitive_attr_t *attr) { \
        return !input_d.has_runtime_dims_or_strides() \
                && simple_attr_check(attr, false, true) \
                && (order_keep ? output_d.matches_tag(tag_o) \
                                        && input_d.is_plain() \
                               : input_d.matches_tag(tag_o) \
                                        && output_d.is_plain()); \
    }

template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<tag_i == format_tag::any
                && (tag_traits<tag_o>::block_dims == bd::_A
                        || tag_traits<tag_o>::block_dims == bd::_B)
                && tag_traits<tag_o>::ndims >= 3
                && tag_traits<tag_o>::ndims <= 6>::type> {
    PLAIN_TO_BLOCKED_IS_APPLICABLE();

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();

        const auto &flat_d = order_keep ? input_d : output_d;
        const auto &block_d = order_keep ? output_d : input_d;
        const auto &dims = input_d.dims();
        const auto &pdims = block_d.padded_dims();

        constexpr int ndims = tag_traits<tag_o>::ndims;
        constexpr int blk_idx = tag_traits<tag_o>::block_dims == bd::_A ? 0 : 1;

        const dim_t H0 = dims[0];
        const dim_t H1 = dims[1];
        const dim_t M0 = ndims >= 6 ? dims[ndims - 4] : 1;
        const dim_t M1 = ndims >= 5 ? dims[ndims - 3] : 1;
        const dim_t M2 = ndims >= 4 ? dims[ndims - 2] : 1;
        const dim_t L = dims[ndims - 1];
        const dim_t l_blk_stride = block_d.blocking_desc().strides[ndims - 1];
        const dim_t l_flat_stride = flat_d.blocking_desc().strides[ndims - 1];
        const dim_t blk_flat_stride = flat_d.blocking_desc().strides[blk_idx];
        using namespace data_type;
        using namespace utils;

        constexpr int blksize = false
                ? 0
                : one_of(tag_traits<tag_o>::inner_blks, ib::_4a, ib::_4b)
                        ? 4
                        : one_of(tag_traits<tag_o>::inner_blks, ib::_8a,
                                  ib::_8b)
                                ? 8
                                : 16;

        constexpr bool f32bf16
                = one_of(type_i, f32, bf16) && one_of(type_o, f32, bf16);

        auto wrap_qz_a1b0 = [=](data_t<type_o> &out, data_t<type_i> inp) {
            if (f32bf16)
                out = inp;
            else
                out = _qz_a1b0<type_i, type_o>()(inp);
        };

        auto wrap_qz = [=](data_t<type_o> &out, data_t<type_i> inp, float alpha,
                               float beta) {
            if (f32bf16)
                out = alpha * inp + (beta ? beta * out : 0);
            else
                out = _qz<type_i, type_o>()(inp, out, alpha, beta);
        };

        auto ker = [&](const data_t<type_i> *i, data_t<type_o> *o, int block) {
            if (alpha == 1.0 && beta == 0.0) {
                for (int l = 0; l < L; ++l) {
                    for (int blk = 0; blk < block; ++blk) {
                        const dim_t flat_off
                                = blk * blk_flat_stride + l * l_flat_stride;
                        const dim_t blk_offset = l * l_blk_stride + blk;
                        if (order_keep) {
                            wrap_qz_a1b0(o[blk_offset], i[flat_off]);
                        } else {
                            wrap_qz_a1b0(o[flat_off], i[blk_offset]);
                        }
                    }
                    if (order_keep) {
                        // zero padding
                        const auto pad_start = block + l * l_blk_stride;
                        const auto pad_end = blksize + l * l_blk_stride;
                        PRAGMA_OMP_SIMD()
                        for (int i = pad_start; i < pad_end; ++i) {
                            o[i] = 0;
                        }
                    }
                }
            } else {
                for (int l = 0; l < L; ++l) {
                    for (int blk = 0; blk < block; ++blk) {
                        const dim_t flat_off
                                = blk * blk_flat_stride + l * l_flat_stride;
                        const dim_t blk_offset = l * l_blk_stride + blk;
                        if (order_keep)
                            wrap_qz(o[blk_offset], i[flat_off], alpha, beta);
                        else
                            wrap_qz(o[flat_off], i[blk_offset], alpha, beta);
                    }
                    if (order_keep) {
                        // zero padding
                        const auto pad_start = block + l * l_blk_stride;
                        const auto pad_end = blksize + l * l_blk_stride;
                        PRAGMA_OMP_SIMD()
                        for (int i = pad_start; i < pad_end; ++i) {
                            o[i] = 0;
                        }
                    }
                }
            }
        };

#define off(md, h0, h1, m0, m1, m2) \
    (ndims >= 6 ? (md).blk_off(h0, h1, m0, m1, m2) \
                : ndims >= 5 ? (md).blk_off(h0, h1, m1, m2) \
                             : ndims >= 4 \
                                    ? (md).blk_off(h0, h1, m2) \
                                    : /* ndims >= 3 ? */ (md).blk_off(h0, h1))

        constexpr int i_mult = order_keep ? blksize : 1;
        constexpr int o_mult = order_keep ? 1 : blksize;

        if (blk_idx == 0) {
            const dim_t BH0 = pdims[0] / blksize;
            parallel_nd(BH0, H1, M0, M1, M2,
                    [&](dim_t bh0, dim_t h1, dim_t m0, dim_t m1, dim_t m2) {
                        auto i = &input[off(
                                input_d, bh0 * i_mult, h1, m0, m1, m2)];
                        auto o = &output[off(
                                output_d, bh0 * o_mult, h1, m0, m1, m2)];
                        const int block
                                = nstl::min<int>(blksize, H0 - bh0 * blksize);
                        ker(i, o, block);
                    });
        } else if (blk_idx == 1) {
            const dim_t BH1 = pdims[1] / blksize;
            parallel_nd(H0, BH1, M0, M1, M2,
                    [&](dim_t h0, dim_t bh1, dim_t m0, dim_t m1, dim_t m2) {
                        auto i = &input[off(
                                input_d, h0, bh1 * i_mult, m0, m1, m2)];
                        auto o = &output[off(
                                output_d, h0, bh1 * o_mult, m0, m1, m2)];
                        const int block
                                = nstl::min<int>(blksize, H1 - bh1 * blksize);
                        ker(i, o, block);
                    });
        } else {
            assert(!"unimplemented");
        }

#undef off

        return status::success;
    }
};

template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<tag_i == format_tag::any
                && (tag_traits<tag_o>::block_dims == bd::_AB
                        || tag_traits<tag_o>::block_dims == bd::_BC)
                && IMPLICATION(tag_traits<tag_o>::block_dims == bd::_AB,
                        tag_traits<tag_o>::ndims >= 3
                                && tag_traits<tag_o>::ndims <= 5)
                && IMPLICATION(tag_traits<tag_o>::block_dims == bd::_BC,
                        tag_traits<tag_o>::ndims >= 4
                                && tag_traits<tag_o>::ndims <= 6)>::type> {
    PLAIN_TO_BLOCKED_IS_APPLICABLE();

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();

        const auto &flat_d = order_keep ? input_d : output_d;
        const auto &dims = input_d.dims();
        const auto &pdims
                = order_keep ? output_d.padded_dims() : input_d.padded_dims();

        constexpr int ndims = tag_traits<tag_o>::ndims;

        static constexpr bool with_g = tag_traits<tag_o>::block_dims == bd::_BC;
        const dim_t G = with_g ? dims[0] : 1;

        const dim_t H0 = dims[0 + with_g];
        const dim_t H1 = dims[1 + with_g];

        const dim_t M0 = ndims >= 5 + with_g ? dims[ndims - 3] : 1;
        const dim_t M1 = ndims >= 4 + with_g ? dims[ndims - 2] : 1;
        const dim_t M2 = ndims >= 3 + with_g ? dims[ndims - 1] : 1;

        const dim_t h0_flat_stride = flat_d.blocking_desc().strides[with_g + 0];
        const dim_t h1_flat_stride = flat_d.blocking_desc().strides[with_g + 1];
        using namespace data_type;
        using namespace utils;

        constexpr int blksize_0 = false
                ? 0
                : one_of(tag_traits<tag_o>::inner_blks, ib::_4b4a, ib::_4b4c,
                          ib::_4c4b)
                        ? 4
                        : one_of(tag_traits<tag_o>::inner_blks, ib::_8a8b,
                                  ib::_8b8a, ib::_8b8c, ib::_8c8b, ib::_2c8b4c)
                                ? 8
                                : one_of(tag_traits<tag_o>::inner_blks,
                                          ib::_16a16b, ib::_16b16a, ib::_16b16c,
                                          ib::_16c16b, ib::_8a16b2a,
                                          ib::_4b16a4b, ib::_8b16a2b,
                                          ib::_8b16c2b, ib::_4c16b4c,
                                          ib::_8c16b2c)
                                        ? 16
                                        : -1;

        constexpr int blksize_1
                = one_of(tag_traits<tag_o>::inner_blks, ib::_8a8b, ib::_8b8a,
                          ib::_8b8c, ib::_8c8b, ib::_2c8b4c)
                ? 8
                : one_of(tag_traits<tag_o>::inner_blks, ib::_16a16b,
                          ib::_16b16a, ib::_16b16c, ib::_16c16b, ib::_8a16b2a,
                          ib::_4b16a4b, ib::_8b16a2b, ib::_8b16c2b,
                          ib::_4c16b4c, ib::_8c16b2c)
                        ? 16
                        : one_of(tag_traits<tag_o>::inner_blks, ib::_4b4a,
                                  ib::_4b4c, ib::_4c4b)
                                ? 4
                                : -1;

        const dim_t NB_H0 = pdims[0 + with_g] / blksize_0;
        const dim_t NB_H1 = pdims[1 + with_g] / blksize_1;

        constexpr bool f32bf16
                = one_of(type_i, f32, bf16) && one_of(type_o, f32, bf16);

        auto wrap_qz_a1b0 = [=](data_t<type_o> &out, data_t<type_i> inp) {
            if (f32bf16)
                out = inp;
            else
                out = _qz_a1b0<type_i, type_o>()(inp);
        };

        auto wrap_qz = [=](data_t<type_o> &out, data_t<type_i> inp, float alpha,
                               float beta) {
            if (f32bf16)
                out = alpha * inp + (beta ? beta * out : 0);
            else
                out = _qz<type_i, type_o>()(inp, out, alpha, beta);
        };

        auto ker = [&](const data_t<type_i> *i, data_t<type_o> *o,
                           const int block_h0, const int block_h1) {
#define blk_off AB_or_BC_blk_off<tag_traits<tag_o>::inner_blks>
            if (alpha == 1.0 && beta == 0.0) {
                for (int h0 = 0; h0 < block_h0; ++h0) {
                    for (int h1 = 0; h1 < block_h1; ++h1) {
                        const dim_t flat_off
                                = h0 * h0_flat_stride + h1 * h1_flat_stride;
                        if (order_keep)
                            wrap_qz_a1b0(o[blk_off(h0, h1)], i[flat_off]);
                        else
                            wrap_qz_a1b0(o[flat_off], i[blk_off(h0, h1)]);
                    }
                    if (order_keep && block_h1 < blksize_1) {
                        // zero padding
                        PRAGMA_OMP_SIMD()
                        for (int h1 = block_h1; h1 < blksize_1; h1++) {
                            o[blk_off(h0, h1)] = 0;
                        }
                    }
                }
                if (order_keep && block_h0 < blksize_0) {
                    // zero padding
                    for (int h0 = block_h0; h0 < blksize_0; h0++) {
                        PRAGMA_OMP_SIMD()
                        for (int h1 = 0; h1 < blksize_1; ++h1) {
                            o[blk_off(h0, h1)] = 0;
                        }
                    }
                }
            } else {
                for (int h0 = 0; h0 < block_h0; ++h0) {
                    for (int h1 = 0; h1 < block_h1; ++h1) {
                        const dim_t flat_off
                                = h0 * h0_flat_stride + h1 * h1_flat_stride;
                        if (order_keep)
                            wrap_qz(o[blk_off(h0, h1)], i[flat_off], alpha,
                                    beta);
                        else
                            wrap_qz(o[flat_off], i[blk_off(h0, h1)], alpha,
                                    beta);
                    }
                    if (order_keep && block_h1 < blksize_1) {
                        // zero padding
                        PRAGMA_OMP_SIMD()
                        for (int h1 = block_h1; h1 < blksize_1; h1++) {
                            o[blk_off(h0, h1)] = 0;
                        }
                    }
                }
                if (order_keep && block_h0 < blksize_0) {
                    // zero padding
                    for (int h0 = block_h0; h0 < blksize_0; h0++) {
                        PRAGMA_OMP_SIMD()
                        for (int h1 = 0; h1 < blksize_1; ++h1) {
                            o[blk_off(h0, h1)] = 0;
                        }
                    }
                }
            }

#undef blk_off
        };

        constexpr int i_mult_0 = order_keep ? blksize_0 : 1;
        constexpr int o_mult_0 = order_keep ? 1 : blksize_0;

        constexpr int i_mult_1 = order_keep ? blksize_1 : 1;
        constexpr int o_mult_1 = order_keep ? 1 : blksize_1;

#define off(md, g, h0, h1, m0, m1, m2) \
    (ndims >= 5 + with_g ? (md).blk_off<!with_g>(g, h0, h1, m0, m1, m2) \
                         : ndims >= 4 + with_g \
                            ? (md).blk_off<!with_g>(g, h0, h1, m1, m2) \
                            : /* ndims >= 3 + with_g ? */ (md) \
                                      .blk_off<!with_g>(g, h0, h1, m2))

        parallel_nd(G, NB_H0, NB_H1, M0, M1, M2,
                [&](dim_t g, dim_t nb_h0, dim_t nb_h1, dim_t m0, dim_t m1,
                        dim_t m2) {
                    auto i = &input[off(input_d, g, i_mult_0 * nb_h0,
                            i_mult_1 * nb_h1, m0, m1, m2)];
                    auto o = &output[off(output_d, g, o_mult_0 * nb_h0,
                            o_mult_1 * nb_h1, m0, m1, m2)];
                    const int block_h0
                            = nstl::min<int>(blksize_0, H0 - nb_h0 * blksize_0);
                    const int block_h1
                            = nstl::min<int>(blksize_1, H1 - nb_h1 * blksize_1);
                    ker(i, o, block_h0, block_h1);
                });

#undef off

        return status::success;
    }
};

/* generic and direct-copy reorders */

template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<tag_i == format_tag::any
                        && tag_o == format_tag::any
                        && order_keep == fmt_order::any,
                spec::direct_copy>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        /* FIXME: is the formula correct? */
        return !input_d.has_runtime_dims_or_strides()
                && input_d.similar_to(output_d, true, false, 0)
                && input_d.is_dense() && output_d.is_dense()
                && simple_attr_check(attr, false, true);
    }

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();

        assert(input_d.is_dense());

        input += input_d.blk_off(0);
        output += output_d.blk_off(0);

        const size_t nelems = input_d.nelems();

        constexpr int block_size = 16;
        const auto num_blocks = nelems / block_size;
        const auto rem_elems = nelems % block_size;

        parallel(0, [&](const int ithr, const int nthr) {
            size_t start {0}, end {0};
            balance211(num_blocks, nthr, ithr, start, end);
            start = start * block_size;
            end = end * block_size;

            if (alpha == 1.0 && beta == 0.0) {
                PRAGMA_OMP_SIMD()
                for (size_t e = start; e < end; ++e) {
                    output[e] = qz_a1b0<data_t<type_i>, data_t<type_o>>()(
                            input[e]);
                }
            } else if (alpha == 1.0) {
                PRAGMA_OMP_SIMD()
                for (size_t e = start; e < end; ++e) {
                    output[e] = qz_a1<data_t<type_i>, data_t<type_o>>()(
                            input[e], output[e], beta);
                }
            } else if (beta == 0.0) {
                PRAGMA_OMP_SIMD()
                for (size_t e = start; e < end; ++e) {
                    output[e] = qz_b0<data_t<type_i>, data_t<type_o>>()(
                            input[e], alpha);
                }
            } else {
                PRAGMA_OMP_SIMD()
                for (size_t e = start; e < end; ++e) {
                    output[e] = qz<data_t<type_i>, data_t<type_o>>()(
                            input[e], output[e], alpha, beta);
                }
            }

            if (rem_elems != 0 && ithr == nthr - 1) {
                if (alpha == 1.0 && beta == 0.0) {
                    PRAGMA_OMP_SIMD()
                    for (size_t e = nelems - rem_elems; e < nelems; ++e) {
                        output[e] = qz_a1b0<data_t<type_i>, data_t<type_o>>()(
                                input[e]);
                    }
                } else if (alpha == 1.0) {
                    PRAGMA_OMP_SIMD()
                    for (size_t e = nelems - rem_elems; e < nelems; ++e) {
                        output[e] = qz_a1<data_t<type_i>, data_t<type_o>>()(
                                input[e], output[e], beta);
                    }
                } else if (beta == 0.0) {
                    PRAGMA_OMP_SIMD()
                    for (size_t e = nelems - rem_elems; e < nelems; ++e) {
                        output[e] = qz_b0<data_t<type_i>, data_t<type_o>>()(
                                input[e], alpha);
                    }
                } else {
                    PRAGMA_OMP_SIMD()
                    for (size_t e = nelems - rem_elems; e < nelems; ++e) {
                        output[e] = qz<data_t<type_i>, data_t<type_o>>()(
                                input[e], output[e], alpha, beta);
                    }
                }
            }
        });
        return status::success;
    }
};

template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<tag_i == format_tag::any
                        && tag_o == format_tag::any
                        && order_keep == fmt_order::any,
                spec::direct_copy_except_dim_0>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        auto is_dense_no_0 = [](const memory_desc_wrapper &data_d) {
            return nelems_no_dim_0(data_d) == _size_no_dim_0(data_d);
        };
        /* FIXME: is the formula correct? */
        return !input_d.has_runtime_dims_or_strides()
                && input_d.similar_to(output_d, true, false, 1)
                && is_dense_no_0(input_d) && is_dense_no_0(output_d)
                && simple_attr_check(attr, false, true);
    }

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(const cpu_reorder_pd_t *pd, const exec_ctx_t &ctx) {
        DECLARE_COMMON_PARAMS();
        using namespace utils;

        input += input_d.blk_off(0);
        output += output_d.blk_off(0);

        const int N = input_d.dims()[0];
        const dim_t is = input_d.blocking_desc().strides[0];
        const dim_t os = output_d.blocking_desc().strides[0];
        const dim_t nelems_no_d0 = nelems_no_dim_0(input_d);
        const dim_t work_amount = N * nelems_no_d0;

        if (alpha == 1.0 && beta == 0.0) {
            parallel(0, [&](const int ithr, const int nthr) {
                dim_t n {0}, dim1_s {0};
                dim_t start {0}, end {0};
                balance211(work_amount, nthr, ithr, start, end);
                nd_iterator_init(start, n, N, dim1_s, nelems_no_d0);
                while (start < end) {
                    dim_t work_rem = end - start;
                    dim_t dim1_e = dim1_s + work_rem > nelems_no_d0
                            ? nelems_no_d0
                            : dim1_s + work_rem;
                    PRAGMA_OMP_SIMD()
                    for (dim_t e = dim1_s; e < dim1_e; ++e) {
                        output[os * n + e]
                                = _qz_a1b0<type_i, type_o>()(input[is * n + e]);
                    }
                    nd_iterator_jump(start, end, n, N, dim1_s, nelems_no_d0);
                }
            });
        } else {
            parallel(0, [&](const int ithr, const int nthr) {
                dim_t n {0}, dim1_s {0};
                dim_t start {0}, end {0};
                balance211(work_amount, nthr, ithr, start, end);
                nd_iterator_init(start, n, N, dim1_s, nelems_no_d0);
                while (start < end) {
                    dim_t work_rem = end - start;
                    dim_t dim1_e = dim1_s + work_rem > nelems_no_d0
                            ? nelems_no_d0
                            : dim1_s + work_rem;
                    PRAGMA_OMP_SIMD()
                    for (dim_t e = dim1_s; e < dim1_e; ++e) {
                        output[os * n + e]
                                = _qz<type_i, type_o>()(input[is * n + e],
                                        output[os * n + e], alpha, beta);
                    }
                    nd_iterator_jump(start, end, n, N, dim1_s, nelems_no_d0);
                }
            });
        }

        return status::success;
    }

private:
    static dim_t nelems_no_dim_0(const memory_desc_wrapper &data_d) {
        const int ndims = data_d.ndims();
        if (ndims <= 1) return 1;
        return utils::array_product(data_d.dims() + 1, data_d.ndims() - 1);
    }

    static dim_t _size_no_dim_0(const memory_desc_wrapper &data_d) {
        dims_t blocks;
        data_d.compute_blocks(blocks);

        const auto &blk = data_d.blocking_desc();

        dim_t blk_size = 1;
        for (int iblk = 0; iblk < blk.inner_nblks; ++iblk)
            blk_size *= blk.inner_blks[iblk];

        dim_t max_size = blk_size;
        for (int d = 1; d < data_d.ndims(); ++d) {
            max_size = nstl::max(max_size,
                    data_d.padded_dims()[d] / blocks[d] * blk.strides[d]);
        }

        return max_size;
    }
};

template <SIMPLE_REORDER_TEMPL_DECL>
struct simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
        typename utils::enable_if<tag_i == format_tag::any
                        && tag_o == format_tag::any
                        && order_keep == fmt_order::any,
                spec::reference>::type> {
    static bool is_applicable(const memory_desc_wrapper &input_d,
            const memory_desc_wrapper &output_d, const primitive_attr_t *attr) {
        /* supported smask: 0x0...011..10...0,
         * i.e. 1 should be contiguous */
        int smask = attr ? attr->output_scales_.mask_ : 0;
        for (; smask > 0 && !(smask & 0x1); smask >>= 1)
            ;
        for (; smask > 0 && smask & 0x1; smask >>= 1)
            ;
        return input_d.is_blocking_desc() && output_d.is_blocking_desc()
                && !output_d.is_additional_buffer()
                && !input_d.is_additional_buffer() && smask == 0
                && attr->has_default_values(
                        dnnl_primitive_attr::skip_mask_t::oscale_runtime
                        | dnnl_primitive_attr::skip_mask_t::zero_points_runtime
                        | dnnl_primitive_attr::skip_mask_t::post_ops)
                && simple_po_check(attr);
    }

    GET_SCRATCHPAD_SIZE_ZERO();

    static status_t execute(
            const cpu_reorder_pd_t *pd_object, const exec_ctx_t &ctx) {
        // DEFINE_SCALES_BUFFER and DEFINE_ZERO_POINT_VALUE macro use pd() to
        // query properties, hence wrapping the primitive descriptor into a
        // function.
        auto pd = [pd_object]() { return pd_object; };

        auto input = CTX_IN_MEM(const data_t<type_i> *, DNNL_ARG_FROM);
        auto output = CTX_OUT_MEM(data_t<type_o> *, DNNL_ARG_TO);

        const float beta = pd()->beta();
        DEFINE_SCALES_BUFFER(scales);
        DEFINE_ZERO_POINT_VALUE(i0, DNNL_ARG_FROM);
        DEFINE_ZERO_POINT_VALUE(o0, DNNL_ARG_TO);

        const auto input_d = ctx.memory_mdw(DNNL_ARG_FROM, pd()->src_md());
        const auto output_d = ctx.memory_mdw(DNNL_ARG_TO, pd()->dst_md());

        const size_t nelems = input_d.nelems();

        // This kernel is used also for tensors with multiple inner
        // blocks for which generic zero padding must be used.
        // TODO: apply zero padding inside parallel_nd()
        ctx.zero_pad_output(DNNL_ARG_TO);

        int ndims_start = 0, ndims_mask = 0;
        int smask = pd()->attr()->output_scales_.mask_;
        for (; smask > 0 && !(smask & 0x1); smask >>= 1)
            ++ndims_start;
        for (; smask > 0 && smask & 0x1; smask >>= 1)
            ++ndims_mask;
        assert(smask == 0);

        const ptrdiff_t D_start
                = utils::array_product(input_d.dims(), ndims_start);
        const ptrdiff_t D_mask = utils::array_product(
                input_d.dims() + ndims_start, ndims_mask);
        const ptrdiff_t D_rest = nelems / D_start / D_mask;

        parallel_nd(D_start, D_mask, D_rest,
                [&](ptrdiff_t ds, ptrdiff_t dm, ptrdiff_t dr) {
                    const float scale = scales[dm];

                    const size_t e = (ds * D_mask + dm) * D_rest + dr;
                    const auto &i = input[input_d.off_l(e)];
                    auto &o = output[output_d.off_l(e)];

                    float f = scale * ((float)i - i0) + o0;
                    o = _qz<data_type::f32, type_o>()(f, o, 1.f, beta);
                });

        return status::success;
    }
};

/* high level class declaration */

template <SIMPLE_REORDER_TEMPL_DECL, typename spec = void>
struct simple_reorder_t : public primitive_t {
    struct pd_t : public cpu_reorder_pd_t {
        using cpu_reorder_pd_t::cpu_reorder_pd_t;

        DECLARE_COMMON_PD_T("simple:any", simple_reorder_t);

    private:
        static status_t create(reorder_pd_t **reorder_pd, engine_t *engine,
                const primitive_attr_t *attr, engine_t *src_engine,
                const memory_desc_t *src_md, engine_t *dst_engine,
                const memory_desc_t *dst_md) {
            bool args_ok = true && src_md->data_type == type_i
                    && dst_md->data_type == type_o
                    && attr->has_default_values(
                            dnnl_primitive_attr::skip_mask_t::oscale_runtime
                            | dnnl_primitive_attr::skip_mask_t::zero_points
                            | dnnl_primitive_attr::skip_mask_t::
                                    zero_points_runtime
                            | dnnl_primitive_attr::skip_mask_t::post_ops)
                    && simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
                            spec>::is_applicable(src_md, dst_md, attr);
            if (!args_ok) return status::invalid_arguments;

            auto _pd = new pd_t(attr, src_engine->kind(), src_md,
                    dst_engine->kind(), dst_md);
            if (_pd == nullptr) return status::out_of_memory;
            if (_pd->init(engine, src_engine, dst_engine) != status::success) {
                delete _pd;
                return status::unimplemented;
            }

            const size_t scratchpad_sz_
                    = simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL,
                            spec>::get_scratchpad_size(src_md, dst_md);
            auto scratchpad = _pd->scratchpad_registry().registrar();
            scratchpad.book(memory_tracking::names::key_reorder_space,
                    scratchpad_sz_, 1, 16);
            _pd->init_scratchpad_md();
            return safe_ptr_assign(*reorder_pd, _pd);
        }
        friend dnnl::impl::impl_list_item_t;
    };

    simple_reorder_t(const pd_t *apd) : primitive_t(apd) {}

    status_t execute(const exec_ctx_t &ctx) const override {
        return simple_reorder_impl<SIMPLE_REORDER_TEMPL_CALL, spec>::execute(
                pd(), ctx);
    }

private:
    const pd_t *pd() const { return (const pd_t *)primitive_t::pd().get(); }
};

#undef SIMPLE_REORDER_TEMPL_DECL
#undef SIMPLE_REORDER_TEMPL_CALL

} // namespace cpu
} // namespace impl
} // namespace dnnl

#endif

// vim: et ts=4 sw=4 cindent cino+=l0,\:4,N-s
